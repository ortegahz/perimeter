#!/usr/bin/env python3
"""
FastReID PyTorch OSNet Market1501é›†æˆç³»ç»Ÿ - ä¿®å¤ç‰ˆ V4.2
åŸºäºDeepStream 7.1 + osnet_ibn_x1_0_market1501 + 512ç»´ç‰¹å¾æå–
æ”¯æŒRTSPæµå’Œæœ¬åœ°è§†é¢‘æ–‡ä»¶

ã€ä¿®å¤å†…å®¹ã€‘ï¼š
1. ä¿®å¤ALPHA_EMAé”™è¯¯ - ä½¿ç”¨å±€éƒ¨å˜é‡alphaè€Œä¸æ˜¯self.ALPHA_EMA
2. ä¿®å¤person_match_countæœªå®šä¹‰é”™è¯¯ - æ·»åŠ åˆå§‹åŒ–å’Œé€’å¢é€»è¾‘
3. ä¿®å¤prototypeå­—æ®µè®¿é—®é”™è¯¯ - ä½¿ç”¨æ­£ç¡®çš„reid_prototypeå­—æ®µ
4. ä¼˜åŒ–PyTorchæ¨ç†æµç¨‹ - ä½¿ç”¨inference_modeæé«˜æ€§èƒ½
5. æ¸…ç†é‡å¤å¯¼å…¥å’Œæœªå®šä¹‰å˜é‡
6. å¢å¼ºé”™è¯¯å¤„ç†å’Œç»Ÿè®¡åŠŸèƒ½
"""

import argparse
import json
import os
import sys
import time
from collections import defaultdict, deque

import cv2
import gi


def numpy_encoder(obj):
    """è‡ªå®šä¹‰JSONç¼–ç å™¨ï¼Œå¤„ç†NumPyæ•°ç»„å’Œå…¶ä»–éJSONåŸç”Ÿç±»å‹"""
    if isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.bool_):
        return bool(obj)
    elif isinstance(obj, dict):
        return {k: numpy_encoder(v) for k, v in obj.items()}
    elif isinstance(obj, (list, tuple)):
        return [numpy_encoder(item) for item in obj]
    return obj


gi.require_version('Gst', '1.0')
gi.require_version('GstRtspServer', '1.0')
from gi.repository import Gst, GObject, GLib

import pyds
import torch
import torch.nn.functional as F
import torchvision.transforms as transforms
from PIL import Image
import numpy as np
import onnxruntime  # ã€æ–°å¢ã€‘å¯¼å…¥ onnxruntime

# æ·»åŠ FastReIDè·¯å¾„
sys.path.insert(0, '/home/fanrrrrrrr/workspace/aihub/yunhe/fast-reid')
from osnet import OSNet as OSNetIBN, OSBlock

# --- ã€æ–°å¢ã€‘äººè„¸è¯†åˆ«é…ç½® ---
FACE_MODEL_PATH = "/home/fanrrrrrrr/ä¸‹è½½/buffalo_l/w600k_r50.onnx"  # Buffalo_Læ¨¡å‹è·¯å¾„
FACE_FEATURE_DIM = 512  # äººè„¸ç‰¹å¾ç»´åº¦
FACE_SIMILARITY_THRESHOLD = 0.5  # äººè„¸ç›¸ä¼¼åº¦é˜ˆå€¼
FACE_WEIGHT = 0.7  # äººè„¸ç‰¹å¾æƒé‡
REID_WEIGHT = 0.3  # ReIDç‰¹å¾æƒé‡
HYBRID_SCORE_THRESHOLD = 0.6  # æ··åˆå¾—åˆ†é˜ˆå€¼

# DeepStream 7.1 ç‰¹å®šå¸¸é‡
# å‚è€ƒ deepstream-test2ï¼šä½¿ç”¨ç»Ÿä¸€åˆ†è¾¨ç‡ï¼Œé¿å…å¤æ‚çš„åæ ‡è½¬æ¢
MUXER_OUTPUT_WIDTH = 1280  # åŒ¹é…è¾“å…¥è§†é¢‘å®½åº¦
MUXER_OUTPUT_HEIGHT = 720  # åŒ¹é…è¾“å…¥è§†é¢‘é«˜åº¦
TILER_OUTPUT_WIDTH = 2560  # 2ä¸ª1280x720è§†é¢‘å¹¶æ’æ˜¾ç¤ºçš„æ€»å®½åº¦
TILER_OUTPUT_HEIGHT = 720  # ä¿æŒé«˜åº¦ä¸å˜
MODEL_INPUT_WIDTH = 960  # æ¨¡å‹åŸå§‹è¾“å…¥å®½åº¦
MODEL_INPUT_HEIGHT = 544  # æ¨¡å‹åŸå§‹è¾“å…¥é«˜åº¦


def create_default_config(config_path):
    """åˆ›å»ºä¸æ¨¡å‹æ–‡ä»¶åŒ¹é…çš„é…ç½®æ–‡ä»¶"""

    # éªŒè¯æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    model_dir = "./models"
    # å°è¯•ä½¿ç”¨ç°æœ‰çš„å¼•æ“æ–‡ä»¶
    engine_file = f"{model_dir}/resnet34_peoplenet.onnx_b2_gpu0_fp16.engine"
    onnx_file = f"{model_dir}/resnet34_peoplenet.onnx"
    labels_file = f"{model_dir}/labels.txt"

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    engine_exists = os.path.exists(engine_file)
    onnx_exists = os.path.exists(onnx_file)
    labels_exists = os.path.exists(labels_file)

    if not (engine_exists or onnx_exists):
        print(f"âŒ è­¦å‘Š: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼")
        print(f"   å¼•æ“æ–‡ä»¶: {engine_exists}")
        print(f"   ONNXæ–‡ä»¶: {onnx_exists}")
        print(f"   æ ‡ç­¾æ–‡ä»¶: {labels_exists}")

    config_content = f'''[property]
# æ¨¡å‹é…ç½® - ä½¿ç”¨å®é™…å­˜åœ¨çš„æ–‡ä»¶
model-engine-file={engine_file}
onnx-file={onnx_file}
labelfile-path={labels_file}

# è¾“å…¥é…ç½® - ä½¿ç”¨æ¨¡å‹åŸå§‹åˆ†è¾¨ç‡544x960 (æ³¨æ„é¡ºåºï¼šé«˜åº¦;å®½åº¦)
infer-dims=3;544;960
batch-size=1
network-mode=2  # FP16æ¨¡å¼
network-type=0  # æ£€æµ‹ç½‘ç»œ
num-detected-classes=3
interval=0
cluster-mode=1  # NMSèšç±»

# ä¿®å¤è¾¹ç•Œæ¡†è¿‡å¤§çš„å…³é”®é…ç½®
maintain-aspect-ratio=1
symmetric-padding=1
scaling-filter=1  # ä½¿ç”¨åŒçº¿æ€§æ’å€¼
scaling-compute-hw=1  # ä½¿ç”¨GPUåŠ é€Ÿç¼©æ”¾

# è¾“å‡ºé…ç½®
gie-unique-id=1
output-tensor-meta=1

# ç±»åˆ«0 - person (ä¸»è¦æ£€æµ‹ç›®æ ‡)
[class-attrs-0]
pre-cluster-threshold=0.25
topk=100
nms-iou-threshold=0.45
detected-min-w=30
detected-min-h=60
detected-max-w=960
detected-max-h=544

# ç±»åˆ«1 - bag (é™ä½æ£€æµ‹ï¼Œä¸»è¦å…³æ³¨person)
[class-attrs-1]
pre-cluster-threshold=0.8
group-threshold=2
eps=0.5
minBoxes=2
roi-top-offset=0
roi-bottom-offset=0
detected-min-w=50
detected-min-h=50
detected-max-w=200
detected-max-h=200

# ç±»åˆ«2 - face (é™ä½æ£€æµ‹ï¼Œä¸»è¦å…³æ³¨person)
[class-attrs-2]
pre-cluster-threshold=0.8
group-threshold=2
eps=0.5
minBoxes=2
roi-top-offset=0
roi-bottom-offset=0
detected-min-w=30
detected-min-h=30
detected-max-w=150
detected-max-h=150
'''

    with open(config_path, 'w') as f:
        f.write(config_content)
    print(f"âœ… å·²åˆ›å»º/æ›´æ–°é…ç½®æ–‡ä»¶: {config_path}")
    print(f"   å¼•æ“æ–‡ä»¶: {engine_file}")
    print(f"   ONNXæ–‡ä»¶: {onnx_file}")
    print(f"   æ ‡ç­¾æ–‡ä»¶: {labels_file}")


# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
def check_model_files():
    detection_model_dir = "./models"
    detection_model_path = "./models/resnet34_peoplenet.onnx"
    # å°è¯•ä½¿ç”¨ç°æœ‰çš„å¼•æ“æ–‡ä»¶
    detection_engine_path = "./models/resnet34_peoplenet.onnx_b2_gpu0_fp16.engine"

    # æ£€æµ‹æ¨¡å‹æ£€æŸ¥ - ä¼˜å…ˆä½¿ç”¨å¼•æ“æ–‡ä»¶
    if os.path.exists(detection_engine_path):
        print(f"âœ… ä½¿ç”¨å¼•æ“æ–‡ä»¶: {detection_engine_path}")
        return True
    elif os.path.exists(detection_model_path):
        print(f"âœ… ä½¿ç”¨ ONNX æ–‡ä»¶: {detection_model_path}")
        print("ğŸ“ å°†è‡ªåŠ¨ç”Ÿæˆå¼•æ“æ–‡ä»¶")
        return True
    else:
        print(f"âŒ ç¼ºå°‘æ£€æµ‹æ¨¡å‹:")
        print(f"   ONNXæ–‡ä»¶: {detection_model_path}")
        print(f"   å¼•æ“æ–‡ä»¶: {detection_engine_path}")
        print("ğŸ“ å»ºè®®ï¼š")
        print("   1. ç¡®ä¿ ONNX æ¨¡å‹æ–‡ä»¶å­˜åœ¨")
        print("   2. æˆ–è¿è¡Œ deepstream-test3-app ç”Ÿæˆå¼•æ“æ–‡ä»¶")
        print("   3. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æƒé™")
        return False

    # æ ‡ç­¾æ–‡ä»¶æ£€æŸ¥
    labels_file = "./models/labels.txt"
    if not os.path.exists(labels_file):
        print(f"âŒ ç¼ºå°‘æ ‡ç­¾æ–‡ä»¶: {labels_file}")
        return False

    print("âœ… æ£€æµ‹æ¨¡å‹æ–‡ä»¶å·²æ‰¾åˆ°")
    return True


# REIDé…ç½®å¸¸é‡
REID_FEATURE_DIM = 512
REID_SIMILARITY_THRESHOLD = 0.85
ALPHA_TRACK = 0.2  # EMAç³»æ•°ï¼Œç”¨äºtrackçº§ç‰¹å¾èšåˆ

# åŒå±‚é˜ˆå€¼é…ç½® - æ”¹å–„è·¨æ‘„åƒå¤´è¯†åˆ«
REID_REACQUISITION_THRESHOLD = 0.75  # ã€æ–°å¢ã€‘ç”¨äºè·¨æ‘„åƒå¤´å¯»å›çš„è¾ƒä½é˜ˆå€¼
REID_CONFIRMATION_THRESHOLD = 0.88  # ã€ä¿®æ”¹ã€‘ç”¨äºå·²é”å®štrackæŒç»­ç¡®è®¤çš„è¾ƒé«˜é˜ˆå€¼ (å¯ä»¥æ¯”åŸæ¥0.85è¿˜é«˜ä¸€ç‚¹)

PATROL_TIME_WINDOW = 3600
PATROL_MIN_OCCURRENCES = 3
PATROL_MIN_DURATION = 300
MAX_TRACK_HISTORY = 100


# --- ã€æ–°å¢ã€‘FaceFeatureExtractorç±» ---
class FaceFeatureExtractor:
    """å°è£… Buffalo_L ONNX æ¨¡å‹çš„äººè„¸ç‰¹å¾æå–åŠŸèƒ½"""

    def __init__(self, model_path=FACE_MODEL_PATH):
        self.model_path = model_path
        self.input_shape = (112, 112)  # Buffalo_Lè¾“å…¥å°ºå¯¸

        if not os.path.exists(self.model_path):
            raise FileNotFoundError(f"âŒ äººè„¸æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°: {self.model_path}")

        try:
            # ä½¿ç”¨GPUè¿›è¡Œæ¨ç†
            providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
            self.session = onnxruntime.InferenceSession(self.model_path, providers=providers)
            print(f"âœ… æˆåŠŸåŠ è½½äººè„¸æ¨¡å‹: {self.model_path} on {self.session.get_providers()[0]}")

            self.input_name = self.session.get_inputs()[0].name
            self.output_name = self.session.get_outputs()[0].name
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–äººè„¸æ¨¡å‹å¤±è´¥: {e}")
            self.session = None

    def preprocess(self, face_crop):
        """å¯¹äººè„¸å›¾åƒè¿›è¡Œé¢„å¤„ç†"""
        # è°ƒæ•´å¤§å°å¹¶è½¬æ¢ä¸ºRGB
        resized_face = cv2.resize(face_crop, self.input_shape)
        rgb_face = cv2.cvtColor(resized_face, cv2.COLOR_BGR2RGB)

        # å½’ä¸€åŒ–å¹¶è°ƒæ•´ç»´åº¦ HWC -> CHW
        tensor = (rgb_face.astype(np.float32) - 127.5) / 128.0
        tensor = tensor.transpose(2, 0, 1)

        # å¢åŠ æ‰¹æ¬¡ç»´åº¦ CHW -> NCHW
        return np.expand_dims(tensor, axis=0)

    def extract_face_feature(self, face_crop):
        """
        æå–äººè„¸ç‰¹å¾å‘é‡
        face_crop: BGRæ ¼å¼çš„numpyæ•°ç»„
        """
        if self.session is None or face_crop is None or face_crop.size == 0:
            return None

        try:
            # ä½¿ç”¨ä¼˜åŒ–çš„é¢„å¤„ç†æµç¨‹
            input_tensor = self.preprocess(face_crop)

            # ä½¿ç”¨ONNX Runtimeè¿›è¡Œé«˜æ•ˆæ¨ç†
            feature = self.session.run([self.output_name], {self.input_name: input_tensor})[0][0]

            # L2 å½’ä¸€åŒ–ï¼Œå¾—åˆ°å•ä½å‘é‡
            norm = np.linalg.norm(feature)
            if norm == 0:
                return None
            normalized_feature = feature / norm

            # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
            result = normalized_feature.astype(np.float32)
            return result
        except Exception as e:
            print(f"âŒ äººè„¸ç‰¹å¾æå–æ¨ç†å¤±è´¥: {e}")
            return None


class FastReIDDatabase:
    def __init__(self):
        # --- ä¿ç•™æ‰€æœ‰æ—§çš„å±æ€§(V3åŠä»¥å‰) ---
        self.track_cache = {}
        self.person_prototypes = {}
        self.recently_disappeared_tracks = {}
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        # --- æ¨¡å‹ä¸æ¨ç†ç›¸å…³ ---
        self.face_extractor = FaceFeatureExtractor()  # å‡è®¾FaceFeatureExtractorç±»å·²å®šä¹‰
        self.reid_model = None  # å°†åœ¨initialize_reid_modelä¸­è¢«èµ‹å€¼
        self.initialize_reid_model()
        self.transform = transforms.Compose([
            transforms.Resize((256, 128)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

        # --- è°ƒè¯•ä¸ç»Ÿè®¡è®¡æ•°å™¨ ---
        self.person_creation_count = 0
        self.person_match_count = 0  # æ·»åŠ åŒ¹é…æ¬¡æ•°è®¡æ•°å™¨
        self.reid_inference_count = 0
        self.face_inference_count = 0
        self.total_frames_processed = 0

        # ã€æ€§èƒ½ä¼˜åŒ–ã€‘å‘¨æœŸæ€§æ—¥å¿—è®¡æ•°å™¨
        self.log_counter = 0
        self.log_interval = 300  # æ¯300å¸§æ‰“å°ä¸€æ¬¡è¯¦ç»†æ—¥å¿—ï¼ˆçº¦10ç§’ï¼‰

        # --- åŠŸèƒ½å‚æ•° ---
        self.EXTRACT_INTERVAL = 3  # é™ä½é—´éš”ï¼Œä½¿ReIDå¤„ç†æ›´é¢‘ç¹
        self.DISAPPEAR_TIMEOUT = 5.0
        self.CONFIRMATION_COUNT_THRESHOLD = 3

        # ã€æ–°å¢ã€‘è·¨æ‘„åƒå¤´IDä¸€è‡´æ€§ä¼˜åŒ– - åŠ¨æ€é˜ˆå€¼è®¾ç½®
        self.REID_REACQUISITION_THRESHOLD = 0.7  # è·¨æ‘„åƒå¤´å¯»å›é˜ˆå€¼ï¼ˆé™ä½è‡³0.7ï¼ŒåŸ0.75ï¼‰
        self.REID_CONFIRMATION_THRESHOLD = 0.85  # åŒä¸€æ‘„åƒå¤´ç¡®è®¤é˜ˆå€¼ï¼ˆé™ä½è‡³0.85ï¼Œä¿æŒè¾ƒé«˜é¿å…è¯¯å…³è”ï¼‰

        # --- ã€V4 & V4.1 æ ¸å¿ƒå‚æ•°æ•´åˆã€‘åŠ¨æ€EMA ä¸ åˆ†å±‚é‡ç½® ---
        # åŠ¨æ€EMAå‚æ•°
        self.ALPHA_HIGH = 0.7  # åˆå§‹å­¦ä¹ é˜¶æ®µçš„é«˜alphaå€¼
        self.ALPHA_LOW = 0.2  # ç¨³å®šé˜¶æ®µçš„ä½alphaå€¼
        self.ALPHA_DECAY_UPDATES = 15  # ä»é«˜alphaè¡°å‡åˆ°ä½alphaæ‰€éœ€çš„æ›´æ–°æ¬¡æ•°

        # --- ã€æ”¹è¿›1ã€‘è·¨æ‘„åƒå¤´åŸŸè‡ªé€‚åº”ï¼ˆDomain Adaptation Matrixï¼‰---
        # åˆå§‹åŒ–ä¸€ä¸ªNÃ—Nç›¸æœºè½¬æ¢çŸ©é˜µï¼Œè®°å½•ä¸åŒæ‘„åƒå¤´ä¹‹é—´çš„å‡å€¼å·®å¼‚
        # Keyæ ¼å¼: (cam_a, cam_b) è¡¨ç¤ºcam_aåˆ°cam_bçš„ç›¸ä¼¼åº¦è°ƒæ•´å› å­
        self.domain_adaptation_matrix = {
            # ä¸ºå¸¸è§æ‘„åƒå¤´å¯¹è®¾ç½®åˆå§‹è°ƒæ•´å› å­ï¼ˆå¯åœ¨è¿è¡Œæ—¶æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼‰
            (0, 1): 1.05,  # cam0 åˆ° cam1 ç›¸ä¼¼åº¦ä¹˜ 1.05
            (1, 0): 1.03,  # cam1 åˆ° cam0 ç›¸ä¼¼åº¦ä¹˜ 1.03
            (0, 2): 0.98,  # cam0 åˆ° cam2 ç›¸ä¼¼åº¦ä¹˜ 0.98
            (2, 0): 1.02,  # cam2 åˆ° cam0 ç›¸ä¼¼åº¦ä¹˜ 1.02
            (1, 2): 1.01,  # cam1 åˆ° cam2 ç›¸ä¼¼åº¦ä¹˜ 1.01
            (2, 1): 0.99,  # cam2 åˆ° cam1 ç›¸ä¼¼åº¦ä¹˜ 0.99
        }
        self.successful_domain_matches = defaultdict(list)  # è®°å½•æˆåŠŸçš„è·¨æ‘„åƒå¤´åŒ¹é…
        self.learning_rate = 0.01  # åŸŸè‡ªé€‚åº”å­¦ä¹ ç‡
        self.update_interval = 10  # æ¯10å¸§æ›´æ–°ä¸€æ¬¡åŸŸè‡ªé€‚åº”çŸ©é˜µ

        # åˆ†å±‚é‡ç½®/æ¸…ç†å‚æ•°
        self.CONFIDENCE_LEVELS = {
            "TRANSIENT": 0,  # ç¬æ—¶/æ¸¸å®¢: ä»…é å‡ æ¬¡ReIDç¡®è®¤
            "CONFIRMED": 1,  # å·²ç¡®è®¤: é å¤šæ¬¡ç¨³å®šReIDç¡®è®¤
            "FACE_VERIFIED": 2  # äººè„¸å·²éªŒè¯: æœ€é«˜å¯ä¿¡åº¦
        }
        self.INACTIVE_THRESHOLDS = {
            self.CONFIDENCE_LEVELS["TRANSIENT"]: 6 * 3600,  # 6å°æ—¶åæ¸…é™¤
            self.CONFIDENCE_LEVELS["CONFIRMED"]: 24 * 3600,  # 24å°æ—¶åé‡ç½®å­¦ä¹ ç‡
            self.CONFIDENCE_LEVELS["FACE_VERIFIED"]: float('inf')  # æ°¸ä¸è¿‡æœŸ
        }

    #
    # --- ã€V4.1 æ–°å¢/ä¿®æ”¹çš„æ ¸å¿ƒå‡½æ•°ã€‘ ---
    #

    def _calculate_dynamic_alpha(self, update_count):
        """
        ã€V4 åŠŸèƒ½ã€‘æ ¹æ®æ›´æ–°æ¬¡æ•°è®¡ç®—åŠ¨æ€çš„ALPHA_EMAå€¼ã€‚
        """
        # é˜¶æ®µ1: å¿«é€Ÿå­¦ä¹  (åˆšåˆ›å»ºæˆ–åˆšé‡ç½®å)
        if update_count < 5:
            return self.ALPHA_HIGH

        # é˜¶æ®µ2: çº¿æ€§è¡°å‡
        if update_count < (5 + self.ALPHA_DECAY_UPDATES):
            progress = (update_count - 5) / self.ALPHA_DECAY_UPDATES
            alpha = self.ALPHA_HIGH - (self.ALPHA_HIGH - self.ALPHA_LOW) * progress
            return alpha

        # é˜¶æ®µ3: ç¨³å®šå­¦ä¹ 
        return self.ALPHA_LOW

    def _calculate_adaptive_alpha(self, camera_id, person_data):
        """
        ã€V5.0ã€‘ä¸ºæ¯ä¸ªæ‘„åƒå¤´è®¡ç®—è‡ªé€‚åº”çš„ALPHAå€¼
        """
        # åŸºäºæ‘„åƒå¤´çš„æ›´æ–°é¢‘ç‡å’Œè´¨é‡è°ƒæ•´alpha
        camera_updates = person_data['camera_weights'].get(camera_id, 1.0)

        # é«˜é¢‘æ›´æ–°çš„æ‘„åƒå¤´ä½¿ç”¨è¾ƒå°çš„alphaï¼ˆæ›´ç¨³å®šï¼‰
        # ä½é¢‘æ›´æ–°çš„æ‘„åƒå¤´ä½¿ç”¨è¾ƒå¤§çš„alphaï¼ˆå¿«é€Ÿé€‚åº”ï¼‰
        if camera_updates > 10:
            return self.ALPHA_LOW
        elif camera_updates > 5:
            return (self.ALPHA_HIGH + self.ALPHA_LOW) / 2
        else:
            return self.ALPHA_HIGH

    def _update_global_prototype(self, person_id):
        """
        è®¡ç®—å…¨å±€åŸå‹ï¼ˆæ–°å¢è¾…åŠ©æ–¹æ³•ï¼‰
        """
        data = self.person_prototypes[person_id]
        camera_protos = data.get('camera_prototypes', {})
        weights = data.get('camera_weights', {})

        if not camera_protos:
            return

        # åŠ æƒå¹³å‡
        weighted_sum = np.zeros(REID_FEATURE_DIM, dtype=np.float32)
        total_weight = 0.0

        for cam_id, proto in camera_protos.items():
            weight = weights.get(cam_id, 1.0)
            weighted_sum += proto * weight
            total_weight += weight

        if total_weight > 0:
            global_proto = weighted_sum / total_weight
            data['global_prototype'] = global_proto / np.linalg.norm(global_proto)
            print(f"   æ›´æ–°å…¨å±€åŸå‹ï¼Œæ•´åˆ {len(camera_protos)} ä¸ªæ‘„åƒå¤´")

    def cleanup_inactive_prototypes(self):
        """
        ã€V4.1 åŠŸèƒ½ã€‘æ‰§è¡Œåˆ†å±‚æ¸…ç†ï¼š
        - FACE_VERIFIED (Lvl 2): æ°¸ä¸å¤„ç†
        - CONFIRMED (Lvl 1): é•¿æ—¶é—´ä¸æ´»è·ƒåˆ™é‡ç½®å­¦ä¹ ç‡
        - TRANSIENT (Lvl 0): è¾ƒçŸ­æ—¶é—´ä¸æ´»è·ƒåˆ™ç›´æ¥åˆ é™¤
        """
        current_time = time.time()
        ids_to_delete = []
        reset_count = 0

        # ä½¿ç”¨ list(self.person_prototypes.items()) æ¥å…è®¸åœ¨å¾ªç¯ä¸­åˆ é™¤
        for person_id, data in list(self.person_prototypes.items()):
            confidence = data.get('confidence_level', self.CONFIDENCE_LEVELS["TRANSIENT"])
            last_update = data.get('last_update_time', current_time)
            inactive_duration = current_time - last_update

            threshold = self.INACTIVE_THRESHOLDS.get(confidence, float('inf'))

            if inactive_duration > threshold:
                if confidence == self.CONFIDENCE_LEVELS["TRANSIENT"]:
                    ids_to_delete.append(person_id)
                elif confidence == self.CONFIDENCE_LEVELS["CONFIRMED"]:
                    data['update_count'] = 0
                    data['current_alpha'] = self.ALPHA_HIGH
                    reset_count += 1
                    print(f"ğŸ•’ åŸå‹é‡ç½®: {person_id}(Lvl:{confidence}) å› ä¸æ´»è·ƒè€Œè¢«é‡ç½®å­¦ä¹ ç‡ã€‚")

        for person_id in ids_to_delete:
            if person_id in self.person_prototypes:
                del self.person_prototypes[person_id]
                print(f"ğŸ—‘ï¸ è®¿å®¢IDåˆ é™¤: {person_id} å› é•¿æœŸä¸æ´»è·ƒè¢«æ¸…é™¤ã€‚")

        if reset_count > 0 or len(ids_to_delete) > 0:
            print(f"ğŸ§¹ æœ¬æ¬¡æ¸…ç†: é‡ç½®äº† {reset_count} ä¸ªå·²ç¡®è®¤ID, åˆ é™¤äº† {len(ids_to_delete)} ä¸ªè®¿å®¢IDã€‚")

    def update_prototypes(self, person_id, track_id, reid_feature, face_feature=None, camera_id=-1):
        """
        ã€V5.0 ä¼˜åŒ–ç‰ˆã€‘æ”¯æŒå¤šæ‘„åƒå¤´ç‹¬ç«‹åŸå‹ç®¡ç†
        """
        current_time = time.time()

        if person_id not in self.person_prototypes:
            # åˆ›å»ºæ–°äººå‘˜ï¼ˆå…¼å®¹ä¸¤ç§æ•°æ®ç»“æ„ï¼‰
            confidence = self.CONFIDENCE_LEVELS["TRANSIENT"]
            if face_feature is not None:
                confidence = self.CONFIDENCE_LEVELS["FACE_VERIFIED"]

            self.person_prototypes[person_id] = {
                'camera_prototypes': {camera_id: reid_feature} if reid_feature is not None else {},  # æ–°å­—æ®µ
                'global_prototype': reid_feature,  # æ–°å­—æ®µï¼šåˆå§‹æ—¶ç­‰äºç¬¬ä¸€ä¸ªreidç‰¹å¾
                'camera_weights': {camera_id: 1.0} if reid_feature is not None else {},  # æ–°å­—æ®µ
                'prototypes': {camera_id: reid_feature} if reid_feature is not None else {},  # ä¿ç•™æ—§å­—æ®µå…¼å®¹æ€§
                'face_prototype': face_feature,
                'camera_id': camera_id,
                'locked_by': track_id,
                'last_update_time': current_time,
                'update_count': 1,
                'current_alpha': self._calculate_dynamic_alpha(1),
                'confidence_level': confidence,
                'history': deque(maxlen=20),
                # æ–°å¢ç»Ÿè®¡å­—æ®µ
                'first_camera_id': camera_id,
                'camera_appearance_count': {camera_id: 1},
                'last_seen_camera': camera_id
            }
            print(f"ğŸ†• åˆ›å»ºäººå‘˜: {person_id}, Camera:{camera_id}")
        else:
            # æ›´æ–°å·²æœ‰äººå‘˜
            data = self.person_prototypes[person_id]
            update_count = data.get('update_count', 0) + 1
            alpha = self._calculate_dynamic_alpha(update_count)

            data.update({
                'update_count': update_count,
                'current_alpha': alpha,
                'last_update_time': current_time,
                'locked_by': track_id,
                'last_seen_camera': camera_id
            })

            # æ›´æ–°æ‘„åƒå¤´å‡ºç°ç»Ÿè®¡
            if 'camera_appearance_count' not in data:
                data['camera_appearance_count'] = {}
            data['camera_appearance_count'][camera_id] = data['camera_appearance_count'].get(camera_id, 0) + 1

            # æ›´æ–°ReIDåŸå‹
            if reid_feature is not None:
                # ç¡®ä¿camera_prototypeså­—æ®µå­˜åœ¨ï¼ˆå…¼å®¹æ—§æ•°æ®ï¼‰
                if 'camera_prototypes' not in data:
                    data['camera_prototypes'] = {}
                if 'camera_weights' not in data:
                    data['camera_weights'] = {}

                # æ›´æ–°å½“å‰æ‘„åƒå¤´çš„åŸå‹
                if camera_id not in data['camera_prototypes']:
                    data['camera_prototypes'][camera_id] = reid_feature
                    data['camera_weights'][camera_id] = 1.0
                    print(f"   ä¸ºæ‘„åƒå¤´ {camera_id} åˆ›å»ºæ–°åŸå‹")
                else:
                    # EMAæ›´æ–°
                    old_proto = data['camera_prototypes'][camera_id]
                    new_proto = alpha * reid_feature + (1 - alpha) * old_proto
                    data['camera_prototypes'][camera_id] = new_proto / np.linalg.norm(new_proto)
                    # å¢åŠ æƒé‡ï¼ˆæœ€å¤šåˆ°2.0ï¼‰
                    data['camera_weights'][camera_id] = min(data['camera_weights'][camera_id] + 0.05, 2.0)
                    print(f"   æ›´æ–°æ‘„åƒå¤´ {camera_id} åŸå‹ï¼ŒAlpha:{alpha:.3f}")

                # æ›´æ–°å…¨å±€åŸå‹ï¼ˆæ‰€æœ‰æ‘„åƒå¤´åŸå‹çš„åŠ æƒå¹³å‡ï¼‰
                self._update_global_prototype(person_id)

                # åŒæ—¶æ›´æ–°æ—§çš„prototypeså­—æ®µï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
                data['prototypes'] = data['camera_prototypes'].copy()

            # æ›´æ–°äººè„¸åŸå‹
            if face_feature is not None:
                if data.get('face_prototype') is None:
                    data['face_prototype'] = face_feature
                    print(f"   æ·»åŠ äººè„¸ç‰¹å¾")
                else:
                    face_alpha = 0.3
                    old_face = data['face_prototype']
                    new_face = face_alpha * face_feature + (1 - face_alpha) * old_face
                    data['face_prototype'] = new_face / np.linalg.norm(new_face)
                    print(f"   æ›´æ–°äººè„¸ç‰¹å¾ï¼ŒAlpha:{face_alpha:.3f}")

            # æ£€æŸ¥æ˜¯å¦å®ç°è·¨æ‘„åƒå¤´ç¡®è®¤
            if len(data.get('camera_appearance_count', {})) >= 2:
                data['cross_camera_confirmed'] = True
                print(f"   âœ… è·¨æ‘„åƒå¤´ç¡®è®¤ï¼å‡ºç°åœ¨ {len(data['camera_appearance_count'])} ä¸ªæ‘„åƒå¤´")

    #
    # --- ã€ä¿ç•™å¹¶é€‚é… V3 çš„æ ¸å¿ƒå¤„ç†é€»è¾‘ã€‘ ---
    #

    def initialize_reid_model(self):
        """åˆå§‹åŒ–çœŸæ­£çš„OSNet-IBNæ¨¡å‹"""
        try:
            # è®¾ç½®æ¨¡å‹è·¯å¾„
            self.model_path = "/home/fanrrrrrrr/workspace/aihub/yunhe/reid_models"
            self.model_file = "osnet_ibn_x1_0_market1501_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip_jitter.pth"
            self.full_path = os.path.join(self.model_path, self.model_file)

            if not os.path.exists(self.full_path):
                print(f"âš ï¸ æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°: {self.full_path}")
                print("å°†ä½¿ç”¨å¤‡ç”¨ç‰¹å¾æå–")
                self.reid_model = None
                return

            # åˆ›å»ºçœŸæ­£çš„OSNet-x1.0æ¨¡å‹
            self.reid_model = OSNetIBN(
                blocks=[OSBlock, OSBlock],
                layers=[2, 2, 2],
                channels=[64, 256, 384, 512],
                feature_dim=REID_FEATURE_DIM
            )

            # åŠ è½½æ¨¡å‹æƒé‡
            checkpoint = torch.load(self.full_path, map_location=self.device)

            # å¤„ç†æƒé‡æ ¼å¼
            if isinstance(checkpoint, dict):
                if 'state_dict' in checkpoint:
                    state_dict = checkpoint['state_dict']
                elif 'model' in checkpoint:
                    state_dict = checkpoint['model']
                else:
                    state_dict = checkpoint
            else:
                state_dict = checkpoint

            # åˆ›å»ºæ–°çš„çŠ¶æ€å­—å…¸ï¼ŒåŒ¹é…æˆ‘ä»¬çš„æ¨¡å‹ç»“æ„
            new_state_dict = {}

            # å¤„ç†å±‚åç§°æ˜ å°„
            for key, value in state_dict.items():
                new_key = key

                # ç§»é™¤moduleå‰ç¼€
                new_key = new_key.replace('module.', '')

                # è½¬æ¢é”®åæ ¼å¼
                if new_key.startswith('conv'):
                    # å¤„ç†convå±‚
                    parts = new_key.split('.')
                    if len(parts) >= 3:
                        layer_num = parts[0]  # conv2, conv3, etc.
                        block_idx = parts[1]  # 0, 1, 2, etc.

                        if layer_num in ['conv2', 'conv3', 'conv4']:
                            # å¤„ç†OSBlockå†…éƒ¨çš„æƒé‡
                            if 'conv' in parts[2]:
                                # è½¬æ¢æ ¼å¼
                                new_parts = [layer_num, block_idx]

                                # å¤„ç†convå†…éƒ¨çš„ç»“æ„
                                if 'conv1' in parts[2]:
                                    new_parts.extend(['0', '0'])  # conv1.conv
                                elif 'conv2a' in parts[2]:
                                    new_parts.extend(['0', '1'])  # conv2a
                                elif 'conv2b' in parts[2]:
                                    new_parts.extend(['0', '2'])  # conv2b
                                elif 'conv2c' in parts[2]:
                                    new_parts.extend(['0', '3'])  # conv2c
                                elif 'conv2d' in parts[2]:
                                    new_parts.extend(['0', '4'])  # conv2d
                                elif 'conv3' in parts[2]:
                                    new_parts.extend(['0', '5'])  # conv3

                                # æ·»åŠ å‰©ä½™éƒ¨åˆ†
                                new_parts.extend(parts[3:])
                                new_key = '.'.join(new_parts)

                # å¤„ç†fcå±‚
                if new_key.startswith('fc'):
                    new_key = new_key.replace('fc.', 'fc.')

                # åªä¿å­˜åŒ¹é…çš„æƒé‡
                if 'classifier' not in new_key:  # è·³è¿‡åˆ†ç±»å™¨
                    new_state_dict[new_key] = value

            # åŠ è½½åŒ¹é…çš„æƒé‡
            model_dict = self.reid_model.state_dict()

            # è¿‡æ»¤å‡ºå½¢çŠ¶åŒ¹é…çš„æƒé‡
            matched_dict = {}
            for key, value in new_state_dict.items():
                if key in model_dict and value.shape == model_dict[key].shape:
                    matched_dict[key] = value

            # åŠ è½½æƒé‡
            model_dict.update(matched_dict)
            missing, unexpected = self.reid_model.load_state_dict(model_dict, strict=False)

            if missing:
                print(f"âš ï¸ ç¼ºå¤±æƒé‡: {len(missing)}ä¸ª")
            if unexpected:
                print(f"âš ï¸ æ„å¤–æƒé‡: {len(unexpected)}ä¸ª")

            # ä¿ç•™åˆ†ç±»å±‚ï¼Œç”¨äºå®Œæ•´çš„OSNet-IBNæ¨¡å‹

            self.reid_model.eval()
            self.reid_model.to(self.device)

            print(f"âœ… æˆåŠŸåŠ è½½å®˜æ–¹OSNet-IBN-x1.0æ¨¡å‹")
            print(f"   æ¨¡å‹: {self.model_file}")
            print(f"   è¾“å‡ºç»´åº¦: {REID_FEATURE_DIM}")
            print(f"   æˆåŠŸåŠ è½½æƒé‡: {len(matched_dict)}ä¸ª")

        except Exception as e:
            print(f"âš ï¸ åˆå§‹åŒ–REIDæ¨¡å‹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            print("å°†ä½¿ç”¨å¤‡ç”¨ç‰¹å¾æå–")
            self.reid_model = None

    def extract_person_feature(self, frame, bbox):
        """
        ä»å•å¸§é‡Œæå– 512 ç»´ OSNet ç‰¹å¾ï¼ˆTTA + ä¼˜åŒ–ç‰ˆè¿‡æ»¤ï¼‰
        frame : BGR ndarray
        bbox  : [x, y, w, h]  â€”â€” å·²ç¡®ä¿ bbox åœ¨ç”»é¢èŒƒå›´å†…
        """
        # 1. åŸºæœ¬è£å‰ªåˆæ³•æ€§
        x, y, w, h = map(int, bbox)
        H, W = frame.shape[:2]

        if w <= 10 or h <= 20 or x >= W or y >= H:  # è¿‡æ»¤æ‰æå°çš„æ¡†
            return None

        # 2. ã€æ ¸å¿ƒä¿®æ”¹ã€‘æ”¾å®½å¯¹"è¿‡å®½ / è¿‡ç˜¦"çš„æ¡†çš„é™åˆ¶
        ratio = w / (h + 1e-6)
        # åŸå§‹é™åˆ¶: if ratio > 0.75 or ratio < 0.30:
        # æ–°çš„ã€æ›´å®½æ¾çš„é™åˆ¶ï¼Œå…è®¸æ›´å¹¿æ³›çš„å§¿æ€å’Œæ£€æµ‹è¯¯å·®
        if ratio > 1.2 or ratio < 0.2:
            return None

        # 3. ä¸Šä¸‹å„ç•™ 10 % PADï¼Œé¿å…è£æ‰å¤´/è„š
        pad_h = int(0.10 * h)
        y0 = max(0, y - pad_h)
        y1 = min(H, y + h + pad_h)

        # å·¦å³ä¹Ÿå¢åŠ ä¸€ç‚¹paddingï¼Œé˜²æ­¢èº«ä½“è¢«æˆªæ–­
        pad_w = int(0.05 * w)
        x0 = max(0, x - pad_w)
        x1 = min(W, x + w + pad_w)

        person_crop = frame[y0:y1, x0:x1]

        if person_crop.size == 0:
            return None

        # 4. OSNet å‰å‘æ¨ç†ï¼ˆå«æ°´å¹³ç¿»è½¬ TTAï¼‰
        try:
            if self.reid_model is None:
                return None

            # æ­£å¼ OSNet - ä¼˜åŒ–æ¨ç†æµç¨‹
            crop_rgb = cv2.cvtColor(person_crop, cv2.COLOR_BGR2RGB)
            pil_img = Image.fromarray(crop_rgb)
            tensor = self.transform(pil_img).unsqueeze(0).to(self.device)

            with torch.no_grad():
                # ä½¿ç”¨PyTorchçš„é«˜æ•ˆæ¨ç†æ¨¡å¼
                if hasattr(torch, 'inference_mode'):
                    with torch.inference_mode():
                        feat = self.reid_model(tensor)
                        feat_flip = self.reid_model(torch.flip(tensor, dims=[3]))
                        feat = F.normalize(feat + feat_flip, p=2, dim=1)
                else:
                    # å…¼å®¹æ—§ç‰ˆæœ¬PyTorch
                    feat = self.reid_model(tensor)
                    feat_flip = self.reid_model(torch.flip(tensor, dims=[3]))
                    feat = F.normalize(feat + feat_flip, p=2, dim=1)

            # å°†ç‰¹å¾è½¬æ¢ä¸ºNumPyæ•°ç»„å¹¶ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
            feature = feat.cpu().numpy()[0].astype(np.float32)
            self.reid_inference_count += 1  # å¢åŠ æ¨ç†è®¡æ•°å™¨
            return feature

        except Exception as e:
            print(f"âŒ ReID ç‰¹å¾æå–æ¨ç†å¤±è´¥: {e}")
            return None

    def compute_cosine_similarity(self, feature1, feature2):
        """è®¡ç®—ä¸¤ä¸ªç‰¹å¾çš„ä½™å¼¦ç›¸ä¼¼åº¦"""
        if feature1 is None or feature2 is None:
            return 0.0

        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ï¼šç‚¹ç§¯ / (èŒƒæ•°1 * èŒƒæ•°2)
        dot_product = np.dot(feature1, feature2)
        norm1 = np.linalg.norm(feature1)
        norm2 = np.linalg.norm(feature2)

        # é¿å…é™¤é›¶é”™è¯¯
        if norm1 == 0 or norm2 == 0:
            return 0.0

        cosine_similarity = dot_product / (norm1 * norm2)

        # ç¡®ä¿ç›¸ä¼¼åº¦åœ¨[-1, 1]èŒƒå›´å†…
        cosine_similarity = np.clip(cosine_similarity, -1.0, 1.0)

        return cosine_similarity

    def find_best_matches(self, reid_feature, face_feature, current_track_id=None, active_track_ids=None, camera_id=-1):
        """
        ã€V5.0 ä¼˜åŒ–ç‰ˆã€‘æ”¹è¿›çš„è·¨æ‘„åƒå¤´åŒ¹é…ç­–ç•¥
        ä¿æŒåŸæœ‰æ¥å£ï¼Œå¢å¼ºè·¨æ‘„åƒå¤´è¯†åˆ«èƒ½åŠ›
        """
        if active_track_ids is None:
            active_track_ids = set()

        # è·å–å½“å‰trackçš„ä¿¡æ¯
        track_info = self.track_cache.get(current_track_id, {})
        current_camera_id = camera_id  # ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„camera_id

        print(f"ğŸ” [MATCH-V5] Track {current_track_id}: å¼€å§‹åŒ¹é…æŸ¥è¯¢")
        print(f"   æ‘„åƒå¤´: {current_camera_id}")
        print(f"   åŸå‹æ•°é‡: {len(self.person_prototypes)}")
        print(f"   æ´»è·ƒTracks: {len(active_track_ids)}")

        if not self.person_prototypes:
            return (None, 0.0), (None, 0.0)

        # --- äººè„¸åŒ¹é…ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰---
        best_face_match_id = None
        best_face_sim = 0.0
        if face_feature is not None:
            for person_id, data in self.person_prototypes.items():
                face_proto = data.get('face_prototype')
                if face_proto is not None:
                    sim = self.compute_cosine_similarity(face_feature, face_proto)
                    if sim > best_face_sim:
                        best_face_sim = sim
                        best_face_match_id = person_id

        # --- ReIDåŒ¹é…ï¼ˆæ”¹è¿›ç‰ˆï¼‰---
        best_reid_match_id = None
        best_reid_sim = 0.0
        best_match_type = None  # è®°å½•åŒ¹é…ç±»å‹

        if reid_feature is not None:
            for person_id, data in self.person_prototypes.items():
                # æ£€æŸ¥åŸå‹é”å®šï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                locked_by_track = data.get('locked_by')
                is_locked_by_another = (
                        locked_by_track is not None and
                        locked_by_track in active_track_ids and
                        locked_by_track != current_track_id
                )

                if is_locked_by_another:
                    print(f"ğŸš« [LOCK] è·³è¿‡åŸå‹ {person_id}ï¼Œå·²è¢«Track {locked_by_track} é”å®š")
                    continue

                # ã€æ–°å¢ã€‘è®¡ç®—å¤šç§ç›¸ä¼¼åº¦
                similarities = []

                # 1. æ£€æŸ¥åŒæ‘„åƒå¤´åŸå‹ï¼ˆæœ€å¯é ï¼‰
                camera_prototypes = data.get('camera_prototypes', {})
                if not camera_prototypes:
                    # å…¼å®¹æ—§ç‰ˆæœ¬ï¼šå¦‚æœæ²¡æœ‰camera_prototypesï¼Œå°è¯•ä½¿ç”¨prototypes
                    old_prototypes = data.get('prototypes', {})
                    if old_prototypes:
                        camera_prototypes = old_prototypes

                if current_camera_id in camera_prototypes:
                    same_cam_proto = camera_prototypes[current_camera_id]
                    same_cam_sim = self.compute_cosine_similarity(reid_feature, same_cam_proto)
                    similarities.append(('same_camera', same_cam_sim, 1.0))  # æƒé‡1.0
                    print(f"   åŒæ‘„åƒå¤´åŒ¹é… {person_id}: {same_cam_sim:.3f}")

                # 2. ä½¿ç”¨å…¨å±€åŸå‹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                global_proto = data.get('global_prototype')
                if global_proto is not None:
                    global_sim = self.compute_cosine_similarity(reid_feature, global_proto)
                    similarities.append(('global', global_sim, 0.85))  # æƒé‡0.85
                    print(f"   å…¨å±€åŸå‹åŒ¹é… {person_id}: {global_sim:.3f}")

                # 3. è·¨æ‘„åƒå¤´åŸå‹åŒ¹é…ï¼ˆå¸¦åŸŸè‡ªé€‚åº”è°ƒæ•´ï¼‰
                for cam_id, proto in camera_prototypes.items():
                    if cam_id != current_camera_id:
                        cross_sim = self.compute_cosine_similarity(reid_feature, proto)
                        # ã€æ”¹è¿›1ã€‘åº”ç”¨åŸŸè‡ªé€‚åº”è°ƒæ•´
                        adapt_key = (cam_id, current_camera_id)  # ä»cam_idåˆ°current_camera_idçš„è½¬æ¢
                        adjust = self.domain_adaptation_matrix.get(adapt_key, 1.0)
                        cross_sim_adjusted = cross_sim * adjust
                        similarities.append(('cross_camera', cross_sim_adjusted, 0.7))  # æƒé‡0.7
                        print(
                            f"   è·¨æ‘„åƒå¤´åŒ¹é… {person_id} (cam{cam_id}): {cross_sim:.3f} -> {cross_sim_adjusted:.3f} (è°ƒæ•´:{adjust:.3f})")

                        # ã€æ”¹è¿›1ã€‘è®°å½•è·¨æ‘„åƒå¤´åŒ¹é…çš„æˆåŠŸä¿¡æ¯ï¼Œç”¨äºåç»­å­¦ä¹ 
                        if cross_sim_adjusted > self.REID_CONFIRMATION_THRESHOLD * 0.9:  # è¾ƒé«˜çš„åŒ¹é…é˜ˆå€¼
                            self.successful_domain_matches[adapt_key].append(cross_sim)

                # ã€æ–°å¢ã€‘è®¡ç®—åŠ æƒå¹³å‡ç›¸ä¼¼åº¦
                if similarities:
                    # é€‰æ‹©æœ€ä½³åŒ¹é…æ–¹å¼
                    best_match = max(similarities, key=lambda x: x[1] * x[2])  # è€ƒè™‘æƒé‡
                    match_type, sim_value, weight = best_match

                    # å¦‚æœäººè„¸ä¹ŸåŒ¹é…ï¼Œæå‡ç½®ä¿¡åº¦
                    if best_face_match_id == person_id and best_face_sim > FACE_SIMILARITY_THRESHOLD:
                        sim_value = sim_value * 0.9 + 0.1  # è½»å¾®æå‡
                        print(f"   âœ¨ äººè„¸å¢å¼º {person_id}: +0.1")

                    if sim_value > best_reid_sim:
                        best_reid_sim = sim_value
                        best_reid_match_id = person_id
                        best_match_type = match_type

        # ã€æ–°å¢ã€‘æ ¹æ®åŒ¹é…ç±»å‹è°ƒæ•´é˜ˆå€¼åˆ¤æ–­
        if best_match_type == 'same_camera':
            # åŒæ‘„åƒå¤´ä½¿ç”¨æ ‡å‡†é˜ˆå€¼
            effective_threshold = self.REID_CONFIRMATION_THRESHOLD
        elif best_match_type == 'global':
            # å…¨å±€åŸå‹ä½¿ç”¨ç¨ä½é˜ˆå€¼
            effective_threshold = self.REID_CONFIRMATION_THRESHOLD * 0.95
        else:  # cross_camera
            # è·¨æ‘„åƒå¤´ä½¿ç”¨æ›´ä½é˜ˆå€¼
            effective_threshold = self.REID_REACQUISITION_THRESHOLD

        print(f"âœ… [MATCH-V5] ç»“æœ:")
        print(f"   äººè„¸: {best_face_match_id} ({best_face_sim:.3f})")
        print(
            f"   ReID: {best_reid_match_id} ({best_reid_sim:.3f}, ç±»å‹:{best_match_type}, é˜ˆå€¼:{effective_threshold:.3f})")

        # ã€æ”¹è¿›1ã€‘å®šæœŸæ›´æ–°åŸŸè‡ªé€‚åº”çŸ©é˜µ
        if self.total_frames_processed % self.update_interval == 0:
            self.update_domain_adaptation_matrix()

        # è¿”å›æ—¶ä¿æŒåŸæœ‰æ¥å£
        return (best_face_match_id, best_face_sim), (best_reid_match_id, best_reid_sim)

    def update_domain_adaptation_matrix(self):
        """ã€æ”¹è¿›1ã€‘æ›´æ–°åŸŸè‡ªé€‚åº”çŸ©é˜µ - æ ¹æ®æˆåŠŸåŒ¹é…å­¦ä¹ è°ƒæ•´å› å­"""
        for adapt_key, similarity_scores in self.successful_domain_matches.items():
            if len(similarity_scores) >= 3:  # è‡³å°‘éœ€è¦3ä¸ªæˆåŠŸæ ·æœ¬æ‰æ›´æ–°
                # è®¡ç®—å¹³å‡ç›¸ä¼¼åº¦
                avg_sim = np.mean(similarity_scores)
                # å¦‚æœå¹³å‡ç›¸ä¼¼åº¦è¾ƒä½ï¼Œè¯´æ˜è¯¥æ‘„åƒå¤´å¯¹éœ€è¦è¡¥å¿
                if avg_sim < 0.8:  # è¾ƒä½çš„åŒ¹é…é˜ˆå€¼
                    # å­¦ä¹ è°ƒæ•´æ–¹å‘ï¼šå¦‚æœåŒ¹é…åº¦ä½ï¼Œå¢åŠ è°ƒæ•´å› å­
                    current_adjust = self.domain_adaptation_matrix.get(adapt_key, 1.0)
                    # ä½¿ç”¨å¯å‘å¼æ–¹æ³•ï¼šåŒ¹é…åº¦è¶Šä½ï¼Œè°ƒæ•´å› å­è¶Šå¤§
                    target_adjust = min(1.5, 1.0 + (0.8 - avg_sim) * 0.5)  # æœ€å¤§ä¸è¶…è¿‡1.5
                    # å¹³æ»‘æ›´æ–°
                    new_adjust = current_adjust + self.learning_rate * (target_adjust - current_adjust)
                    self.domain_adaptation_matrix[adapt_key] = new_adjust
                    print(
                        f"ğŸ“Š [DOMAIN-ADAPT] æ›´æ–°åŸŸè‡ªé€‚åº”çŸ©é˜µ {adapt_key}: {current_adjust:.3f} -> {new_adjust:.3f} (åŸºäº{len(similarity_scores)}ä¸ªåŒ¹é…ï¼Œå¹³å‡ç›¸ä¼¼åº¦:{avg_sim:.3f})")
                # æ¸…ç©ºå·²å¤„ç†çš„è®°å½•
                self.successful_domain_matches[adapt_key] = []

        # å®šæœŸæ‰“å°åŸŸè‡ªé€‚åº”çŸ©é˜µçŠ¶æ€
        if self.total_frames_processed % 100 == 0 and self.domain_adaptation_matrix:
            print(f"ğŸ“Š [DOMAIN-ADAPT] å½“å‰åŸŸè‡ªé€‚åº”çŸ©é˜µçŠ¶æ€:")
            for (cam_a, cam_b), adjust in sorted(self.domain_adaptation_matrix.items()):
                print(f"   cam{cam_a}â†’cam{cam_b}: {adjust:.3f}")

    def check_patrol_behavior(self, person_id, current_time):
        """æ£€æŸ¥å¾˜å¾Šè¡Œä¸º"""
        if person_id not in self.person_prototypes:
            return False

        # ã€ä¿®æ”¹ã€‘ä»æ‰€æœ‰æ‘„åƒå¤´çš„åŸå‹ä¸­è·å–ç‰¹å¾
        prototypes = self.person_prototypes[person_id].get('prototypes', {})
        features = list(prototypes.values()) if prototypes else []
        if len(features) < PATROL_MIN_OCCURRENCES:
            return False

        recent_detections = [(current_time, features[0], None)]

        if len(recent_detections) < PATROL_MIN_OCCURRENCES:
            return False

        start_time = current_time - 300  # å‡è®¾5åˆ†é’Ÿå‰å¼€å§‹
        end_time = current_time
        duration = end_time - start_time

        if duration >= PATROL_MIN_DURATION:
            bboxes = [None]  # ä¸´æ—¶é€‚é…
            if self._calculate_patrol_area(bboxes) > 0.1:
                return True

        return False

    def _calculate_patrol_area(self, bboxes):
        """è®¡ç®—äººå‘˜æ´»åŠ¨åŒºåŸŸèŒƒå›´"""
        if not bboxes:
            return 0.0

        x_coords = [b[0] + b[2] / 2 for b in bboxes]
        y_coords = [b[1] + b[3] / 2 for b in bboxes]

        if len(x_coords) < 2:
            return 0.0

        x_range = max(x_coords) - min(x_coords)
        y_range = max(y_coords) - min(y_coords)
        return (x_range * y_range) / (1280 * 720)

    def cleanup_stale_tracks(self, alive_track_ids):
        """ã€ä¼˜åŒ–ç‰ˆã€‘æ¸…ç†trackï¼Œå¹¶å°†æ¶ˆå¤±çš„trackä¿¡æ¯å­˜å…¥"çŸ­æœŸè®°å¿†"ä»¥åº”å¯¹é®æŒ¡"""
        stale_tracks = []
        current_time = time.time()

        # æ‰¾å‡ºæ¶ˆå¤±çš„track
        for track_id in self.track_cache.keys():
            if track_id not in alive_track_ids:
                stale_tracks.append(track_id)

        # å¤„ç†æ¶ˆå¤±çš„track
        for track_id in stale_tracks:
            track_info = self.track_cache.get(track_id)
            if track_info:
                person_id = track_info.get('person_id')
                # åªæœ‰è¢«æˆåŠŸè¯†åˆ«è¿‡çš„äººï¼Œæ‰æœ‰ä»·å€¼è¢«è®°å…¥çŸ­æœŸè®°å¿†
                if person_id and person_id in self.person_prototypes:
                    print(f"ğŸ§  Track {track_id} ({person_id}) æ¶ˆå¤±ï¼Œå­˜å…¥çŸ­æœŸè®°å¿†...")
                    self.recently_disappeared_tracks[track_id] = {
                        'person_id': person_id,
                        'disappeared_time': current_time,
                        # ä¿å­˜æ¶ˆå¤±å‰çš„æœ€åä¸€ä¸ªåŸå‹ï¼Œç”¨äºä¼˜å…ˆæ¯”å¯¹
                        'last_prototype': list(self.person_prototypes[person_id].get('prototypes', {}).values())[0] if
                        self.person_prototypes[person_id].get('prototypes') else None
                    }

            # ä»æ´»è·ƒç¼“å­˜ä¸­åˆ é™¤
            del self.track_cache[track_id]

        # æ¸…ç†"çŸ­æœŸè®°å¿†"ä¸­è¶…æ—¶çš„track
        timeout_tracks = []
        for track_id, data in self.recently_disappeared_tracks.items():
            if current_time - data['disappeared_time'] > self.DISAPPEAR_TIMEOUT:
                timeout_tracks.append(track_id)

        for track_id in timeout_tracks:
            print(f"ğŸ’­ Track {track_id} ä»çŸ­æœŸè®°å¿†ä¸­æ¸…é™¤ (è¶…æ—¶)ã€‚")
            del self.recently_disappeared_tracks[track_id]

    def cleanup_person_registry(self):
        """æ¸…ç†äººå‘˜æ³¨å†Œè¡¨ä¸­çš„è¿‡æœŸæ•°æ® - å·²å¼ƒç”¨ï¼Œä½¿ç”¨æ–°ç»“æ„"""
        # è¿™ä¸ªæ–¹æ³•ç°åœ¨åªä¿ç•™å…¼å®¹æ€§ï¼Œä¸å†æ‰§è¡Œå®é™…æ“ä½œ
        # åŸå‹ç”±cleanup_stale_trackså’Œç³»ç»Ÿé€»è¾‘è‡ªåŠ¨ç®¡ç†
        pass

    def find_in_short_term_memory(self, feature):
        """åœ¨çŸ­æœŸè®°å¿†ä¸­æŸ¥æ‰¾åŒ¹é…é¡¹ï¼Œç”¨äºå¤„ç†é®æŒ¡é‡ç°"""
        if feature is None or not self.recently_disappeared_tracks:
            print(
                f"ğŸ” [MEMORY] çŸ­æœŸè®°å¿†æ£€æŸ¥è·³è¿‡: feature={feature is not None}, è®°å½•æ•°={len(self.recently_disappeared_tracks)}")
            return None, 0.0

        best_match_person_id = None
        best_similarity = 0.0
        matched_disappeared_track_id = None

        print(f"ğŸ” [MEMORY] å¼€å§‹åœ¨çŸ­æœŸè®°å¿†ä¸­æœç´¢ï¼Œè®°å½•æ•°={len(self.recently_disappeared_tracks)}")

        for track_id, data in self.recently_disappeared_tracks.items():
            last_prototype = data.get('last_prototype')
            if last_prototype is None:
                print(f"ğŸ” [MEMORY] è·³è¿‡è®°å½• {track_id}: æ— åŸå‹æ•°æ®")
                continue

            similarity = self.compute_cosine_similarity(feature, last_prototype)

            if similarity > best_similarity:
                best_similarity = similarity
                best_match_person_id = data.get('person_id')
                matched_disappeared_track_id = track_id

        if best_similarity >= self.REID_REACQUISITION_THRESHOLD:
            # æˆåŠŸåœ¨çŸ­æœŸè®°å¿†ä¸­æ‰¾åˆ°åŒ¹é…ï¼
            # ä»çŸ­æœŸè®°å¿†ä¸­ç§»é™¤ï¼Œå› ä¸ºå®ƒå·²ç»è¢«"è®¤é¢†"äº†
            del self.recently_disappeared_tracks[matched_disappeared_track_id]
            return best_match_person_id, best_similarity
        else:
            return None, 0.0

    def save_database(self, filename=None, create_backup=True):
        """
        ã€V5.0 é€‚é…ã€‘ä¿å­˜æ•°æ®åº“æ—¶ï¼Œæ”¯æŒå¤šæ‘„åƒå¤´åŸå‹ç»“æ„
        """
        if filename is None:
            filename = "fastreid_database.json"

        temp_filename = filename + ".tmp"

        try:
            # å‡†å¤‡è¦ä¿å­˜çš„æ•°æ®
            save_data = {
                'version': '5.0',  # æ›´æ–°ç‰ˆæœ¬å·ï¼Œæ ‡è¯†æ–°çš„æ•°æ®ç»“æ„
                'timestamp': time.time(),
                'person_prototypes': {},
                'track_cache': {},
                'person_creation_count': self.person_creation_count,
                'total_frames_processed': getattr(self, 'total_frames_processed', 0),
                'reid_inference_count': getattr(self, 'reid_inference_count', 0),
                'face_inference_count': getattr(self, 'face_inference_count', 0),
                # æ–°å¢æ‘„åƒå¤´ç›¸å…³ç»Ÿè®¡
                'camera_statistics': getattr(self, 'camera_statistics', {}),
                'domain_adaptation_data': getattr(self, 'domain_adaptation_matrix', {})
            }

            # åºåˆ—åŒ–person_prototypesï¼ˆæ”¯æŒV5.0å¤šæ‘„åƒå¤´åŸå‹ï¼‰
            for person_id, data in self.person_prototypes.items():
                # å¤„ç†å¤šæ‘„åƒå¤´åŸå‹
                camera_prototypes_serialized = {}
                camera_protos = data.get('camera_prototypes', {})

                # åºåˆ—åŒ–æ¯ä¸ªæ‘„åƒå¤´çš„åŸå‹
                for cam_id, proto in camera_protos.items():
                    if proto is not None:
                        norm = np.linalg.norm(proto)
                        if norm > 0:
                            proto = proto / norm
                        camera_prototypes_serialized[str(cam_id)] = proto.tolist()

                # åºåˆ—åŒ–å…¨å±€åŸå‹
                global_proto = data.get('global_prototype')
                if global_proto is not None:
                    norm = np.linalg.norm(global_proto)
                    if norm > 0:
                        global_proto = global_proto / norm
                    global_proto_serialized = global_proto.tolist()
                else:
                    global_proto_serialized = None

                # åºåˆ—åŒ–äººè„¸åŸå‹
                face_proto = data.get('face_prototype')
                if face_proto is not None:
                    norm = np.linalg.norm(face_proto)
                    if norm > 0:
                        face_proto = face_proto / norm
                    face_proto_serialized = face_proto.tolist()
                else:
                    face_proto_serialized = None

                # åºåˆ—åŒ–æ‘„åƒå¤´æƒé‡
                camera_weights_serialized = {}
                for cam_id, weight in data.get('camera_weights', {}).items():
                    camera_weights_serialized[str(cam_id)] = float(weight)

                save_data['person_prototypes'][person_id] = {
                    'camera_prototypes': camera_prototypes_serialized,  # å¤šæ‘„åƒå¤´åŸå‹
                    'global_prototype': global_proto_serialized,  # å…¨å±€èåˆåŸå‹
                    'face_prototype': face_proto_serialized,
                    'camera_weights': camera_weights_serialized,  # æ‘„åƒå¤´æƒé‡
                    'locked_by': data.get('locked_by'),
                    'last_update_time': data.get('last_update_time'),
                    'update_count': data.get('update_count', 0),
                    'current_alpha': data.get('current_alpha', self.ALPHA_LOW),
                    'confidence_level': data.get('confidence_level', self.CONFIDENCE_LEVELS["TRANSIENT"]),
                    # æ–°å¢å­—æ®µ
                    'first_camera_id': data.get('first_camera_id', -1),  # é¦–æ¬¡å‡ºç°çš„æ‘„åƒå¤´
                    'camera_appearance_count': data.get('camera_appearance_count', {}),  # å„æ‘„åƒå¤´å‡ºç°æ¬¡æ•°
                    'last_seen_camera': data.get('last_seen_camera', -1),  # æœ€åå‡ºç°çš„æ‘„åƒå¤´
                    'cross_camera_confirmed': data.get('cross_camera_confirmed', False)  # æ˜¯å¦è·¨æ‘„åƒå¤´ç¡®è®¤
                }

            # åºåˆ—åŒ–track_cache
            for track_id, cache_data in self.track_cache.items():
                # ç¡®ä¿track_idæ˜¯å­—ç¬¦ä¸²
                save_data['track_cache'][str(track_id)] = {
                    'person_id': cache_data.get('person_id'),
                    'status': cache_data.get('status'),
                    'camera_id': cache_data.get('camera_id', -1),
                    'last_feat_frame': cache_data.get('last_feat_frame', -1),
                    'confirming_id': cache_data.get('confirming_id'),
                    'confirming_count': cache_data.get('confirming_count', 0)
                }

            # å†™å…¥ä¸´æ—¶æ–‡ä»¶
            with open(temp_filename, 'w') as f:
                json.dump(save_data, f, indent=2, default=numpy_encoder)

            # åŸå­åŒ–æ“ä½œ
            os.replace(temp_filename, filename)

            # åˆ›å»ºå¤‡ä»½
            if create_backup:
                backup_filename = filename.replace('.json', f'_backup_{int(time.time())}.json')
                import shutil
                shutil.copyfile(filename, backup_filename)

            # ç»Ÿè®¡ä¿¡æ¯
            total_cameras = set()
            for person_data in save_data['person_prototypes'].values():
                total_cameras.update(person_data.get('camera_prototypes', {}).keys())

            print(f"ğŸ’¾ V5.0æ•°æ®åº“å·²ä¿å­˜è‡³ {filename}")
            print(f"   äººå‘˜æ•°: {len(save_data['person_prototypes'])}")
            print(f"   æ´»è·ƒTrack: {len(save_data['track_cache'])}")
            print(f"   æ¶‰åŠæ‘„åƒå¤´: {len(total_cameras)}ä¸ª")

            return True

        except Exception as e:
            print(f"âŒ ä¿å­˜æ•°æ®åº“åˆ° {filename} å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            if os.path.exists(temp_filename):
                os.remove(temp_filename)
            return False

    def load_database(self, filename=None):
        """
        ã€V5.0 é€‚é…ã€‘åŠ è½½æ•°æ®åº“ï¼Œæ”¯æŒå‘åå…¼å®¹
        """
        if filename is None:
            filename = "fastreid_database.json"

        if not os.path.exists(filename):
            print(f"â„¹ï¸ æ•°æ®åº“æ–‡ä»¶ {filename} ä¸å­˜åœ¨")
            return False

        try:
            with open(filename, 'r') as f:
                data = json.load(f)

            # æ£€æŸ¥ç‰ˆæœ¬ä»¥ç¡®å®šåŠ è½½ç­–ç•¥
            version = data.get('version', '1.0')
            print(f"ğŸ“‚ åŠ è½½æ•°æ®åº“ç‰ˆæœ¬: {version}")

            self.person_prototypes.clear()
            self.track_cache.clear()

            # å¤„ç†person_prototypes
            for person_id, proto_data in data.get('person_prototypes', {}).items():

                if version >= '5.0':
                    # V5.0æ ¼å¼ï¼šå¤šæ‘„åƒå¤´åŸå‹
                    camera_prototypes = {}
                    for cam_id_str, proto_list in proto_data.get('camera_prototypes', {}).items():
                        if proto_list:
                            camera_prototypes[int(cam_id_str)] = np.array(proto_list, dtype=np.float32)

                    global_proto = None
                    if proto_data.get('global_prototype'):
                        global_proto = np.array(proto_data['global_prototype'], dtype=np.float32)

                    face_proto = None
                    if proto_data.get('face_prototype'):
                        face_proto = np.array(proto_data['face_prototype'], dtype=np.float32)

                    camera_weights = {}
                    for cam_id_str, weight in proto_data.get('camera_weights', {}).items():
                        camera_weights[int(cam_id_str)] = float(weight)

                    self.person_prototypes[person_id] = {
                        'camera_prototypes': camera_prototypes,
                        'global_prototype': global_proto,
                        'face_prototype': face_proto,
                        'camera_weights': camera_weights,
                        'locked_by': proto_data.get('locked_by'),
                        'last_update_time': proto_data.get('last_update_time', time.time()),
                        'update_count': proto_data.get('update_count', 0),
                        'current_alpha': proto_data.get('current_alpha', self.ALPHA_LOW),
                        'confidence_level': proto_data.get('confidence_level', self.CONFIDENCE_LEVELS["TRANSIENT"]),
                        'history': deque(maxlen=20),
                        'first_camera_id': proto_data.get('first_camera_id', -1),
                        'camera_appearance_count': proto_data.get('camera_appearance_count', {}),
                        'last_seen_camera': proto_data.get('last_seen_camera', -1),
                        'cross_camera_confirmed': proto_data.get('cross_camera_confirmed', False)
                    }

                else:
                    # æ—§ç‰ˆæœ¬æ ¼å¼å…¼å®¹ï¼ˆV4.xåŠä»¥ä¸‹ï¼‰
                    print(f"âš ï¸ æ£€æµ‹åˆ°æ—§ç‰ˆæœ¬æ•°æ®ï¼Œè¿›è¡Œæ ¼å¼è½¬æ¢...")

                    # å¤„ç†æ—§ç‰ˆæœ¬çš„å•ä¸€åŸå‹æˆ–prototypeså­—æ®µ
                    reid_proto = None
                    if 'reid_prototype' in proto_data and proto_data['reid_prototype']:
                        reid_proto = np.array(proto_data['reid_prototype'], dtype=np.float32)
                    elif 'prototypes' in proto_data:
                        # V4.3æ ¼å¼
                        prototypes = proto_data['prototypes']
                        if isinstance(prototypes, dict) and prototypes:
                            # å–ç¬¬ä¸€ä¸ªåŸå‹ä½œä¸ºé»˜è®¤
                            first_proto = list(prototypes.values())[0]
                            if first_proto:
                                reid_proto = np.array(first_proto, dtype=np.float32)

                    face_proto = None
                    if proto_data.get('face_prototype'):
                        face_proto = np.array(proto_data['face_prototype'], dtype=np.float32)

                    # è½¬æ¢ä¸ºæ–°æ ¼å¼
                    camera_prototypes = {}
                    if reid_proto is not None:
                        # å‡è®¾åŸå§‹æ‘„åƒå¤´IDä¸º0
                        camera_prototypes[0] = reid_proto

                    self.person_prototypes[person_id] = {
                        'camera_prototypes': camera_prototypes,
                        'global_prototype': reid_proto,  # ä½¿ç”¨å•ä¸€åŸå‹ä½œä¸ºå…¨å±€åŸå‹
                        'face_prototype': face_proto,
                        'camera_weights': {0: 1.0} if camera_prototypes else {},
                        'locked_by': proto_data.get('locked_by'),
                        'last_update_time': proto_data.get('last_update_time', time.time()),
                        'update_count': proto_data.get('update_count', 20),
                        'current_alpha': proto_data.get('current_alpha', self.ALPHA_LOW),
                        'confidence_level': proto_data.get('confidence_level', self.CONFIDENCE_LEVELS["CONFIRMED"]),
                        'history': deque(maxlen=20),
                        'first_camera_id': proto_data.get('camera_id', 0),
                        'camera_appearance_count': {},
                        'last_seen_camera': 0,
                        'cross_camera_confirmed': False
                    }

            # å¤„ç†track_cache
            for track_id_str, cache_data in data.get('track_cache', {}).items():
                # è½¬æ¢track_idä¸ºæ•´æ•°
                try:
                    track_id = int(track_id_str)
                except:
                    track_id = track_id_str

                self.track_cache[track_id] = cache_data

            # æ›´æ–°ç»Ÿè®¡æ•°æ®
            self.person_creation_count = data.get('person_creation_count', len(self.person_prototypes))
            self.total_frames_processed = data.get('total_frames_processed', 0)
            self.reid_inference_count = data.get('reid_inference_count', 0)
            self.face_inference_count = data.get('face_inference_count', 0)

            # åŠ è½½æ–°å¢çš„æ‘„åƒå¤´ç›¸å…³æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
            if version >= '5.0':
                self.camera_statistics = data.get('camera_statistics', {})
                self.domain_adaptation_matrix = data.get('domain_adaptation_data', {})

            # æ›´æ–°person_creation_count
            if self.person_prototypes:
                max_id = max([int(pid.split('_')[-1]) for pid in self.person_prototypes.keys()
                              if pid.startswith('person_')], default=0)
                self.person_creation_count = max(self.person_creation_count, max_id)

            # ç»Ÿè®¡ä¿¡æ¯
            total_persons = len(self.person_prototypes)
            total_cameras = set()
            for person_data in self.person_prototypes.values():
                total_cameras.update(person_data.get('camera_prototypes', {}).keys())

            print(f"âœ… V5.0æ•°æ®åº“åŠ è½½å®Œæˆ: {filename}")
            print(f"   äººå‘˜æ•°: {total_persons}")
            print(f"   æ¶‰åŠæ‘„åƒå¤´: {len(total_cameras)}ä¸ª")
            if version < '5.0':
                print(f"   âš ï¸ å·²ä»ç‰ˆæœ¬ {version} è‡ªåŠ¨å‡çº§åˆ° 5.0")

            return True

        except Exception as e:
            print(f"âŒ æ•°æ®åº“åŠ è½½å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

    def export_database_summary(self, filename="database_summary.txt"):
        """å¯¼å‡ºæ•°æ®åº“æ‘˜è¦"""
        try:
            summary_lines = [
                "FastReID æ•°æ®åº“æ‘˜è¦",
                "=" * 50,
                f"ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}",
                f"æ•°æ®åº“ç‰ˆæœ¬: 2.0",
                f"äººå‘˜åŸå‹: {len(self.person_prototypes)}",
                f"Trackç¼“å­˜: {len(self.track_cache)}",
                f"åˆ›å»ºæ¬¡æ•°: {self.person_creation_count}",
                f"åŒ¹é…æ¬¡æ•°: {getattr(self, 'person_match_count', 0)}",  # ä½¿ç”¨getattré¿å…æœªå®šä¹‰é”™è¯¯
                f"å¤„ç†å¸§æ•°: {self.total_frames_processed}",
                f"æ¨ç†æ¬¡æ•°: {self.reid_inference_count}",
                "",
                "äººå‘˜åŸå‹åˆ—è¡¨:"
            ]

            for person_id in self.person_prototypes.keys():
                locked_by = self.person_prototypes[person_id].get('locked_by', 'None')
                summary_lines.append(f"  - {person_id} (é”å®šè€…: {locked_by})")

            summary_text = "\n".join(summary_lines)

            with open(filename, 'w') as f:
                f.write(summary_text)

            print(f"âœ… æ•°æ®åº“æ‘˜è¦å·²å¯¼å‡º: {filename}")
            print(summary_text)

        except Exception as e:
            print(f"âŒ å¯¼å‡ºæ•°æ®åº“æ‘˜è¦å¤±è´¥: {e}")

    def cleanup_database(self, time_window=3600):
        """æ¸…ç†æ•°æ®åº“ä¸­çš„è¿‡æœŸæ•°æ® - æ–°ç»“æ„"""
        try:
            current_time = time.time()
            cutoff_time = current_time - time_window

            # æ¸…ç†è¿‡æœŸçš„trackç¼“å­˜
            cleaned_tracks = 0
            for track_id in list(self.track_cache.keys()):
                last_frame = self.track_cache[track_id]['last_feat_frame']
                # å¦‚æœè¶…è¿‡ä¸€å®šæ—¶é—´æ²¡æœ‰æ›´æ–°ï¼Œæ¸…ç†trackç¼“å­˜
                if current_time - last_frame > time_window:
                    # é‡Šæ”¾é”å®šçš„åŸå‹
                    person_id = self.track_cache[track_id].get('person_id')
                    if person_id and person_id in self.person_prototypes:
                        if self.person_prototypes[person_id].get('locked_by') == track_id:
                            self.person_prototypes[person_id]['locked_by'] = None
                            print(f"ğŸ”“ æ¸…ç†æ—¶è§£é”åŸå‹: {person_id} (track_id={track_id})")

                    del self.track_cache[track_id]
                    cleaned_tracks += 1
                    print(f"ğŸ§¹ æ¸…ç†è¿‡æœŸtrackç¼“å­˜: {track_id}")

            # æ¸…ç†è¿‡æœŸçš„åŸå‹ï¼ˆå¯é€‰ï¼Œä½†é€šå¸¸ç”±ç³»ç»Ÿé€»è¾‘è‡ªåŠ¨ç®¡ç†ï¼‰
            print(f"âœ… æ•°æ®åº“æ¸…ç†å®Œæˆ")
            print(f"   æ¸…ç†trackç¼“å­˜: {cleaned_tracks} ä¸ª")
            print(f"   å‰©ä½™äººå‘˜åŸå‹: {len(self.person_prototypes)} ä¸ª")
            print(f"   å‰©ä½™trackç¼“å­˜: {len(self.track_cache)} ä¸ª")

            return True

        except Exception as e:
            print(f"âŒ æ¸…ç†æ•°æ®åº“å¤±è´¥: {e}")
            return False

    def get_person_registry_stats(self):
        """è·å–äººå‘˜æ³¨å†Œè¡¨ç»Ÿè®¡ä¿¡æ¯ - æ–°ç»“æ„"""
        total_prototypes = len(self.person_prototypes)
        locked_prototypes = sum(1 for data in self.person_prototypes.values()
                                if data.get('locked_by') is not None)

        return {
            'total_persons': total_prototypes,
            'total_features': total_prototypes,  # æ¯ä¸ªåŸå‹å°±æ˜¯ä¸€ä¸ªç‰¹å¾
            'avg_features_per_person': 1.0,  # æ¯ä¸ªåŸå‹å°±æ˜¯ä¸€ä¸ªç‰¹å¾
            'person_creation_count': self.person_creation_count,
            'person_match_count': getattr(self, 'person_match_count', 0),  # ä½¿ç”¨getattré¿å…æœªå®šä¹‰é”™è¯¯
            'locked_prototypes': locked_prototypes,
            'unlocked_prototypes': total_prototypes - locked_prototypes
        }

    def is_bbox_valid(self, bbox):
        """æ£€æŸ¥bboxæ˜¯å¦æœ‰æ•ˆï¼ˆè¿‡æ»¤è¿‡å°çš„bboxï¼‰"""
        x, y, w, h = bbox
        # æœ€å°å°ºå¯¸è¦æ±‚ï¼š10x20åƒç´ 
        min_area = 10 * 20
        bbox_area = w * h
        return bbox_area >= min_area

    def process_track_v3(self, track_id, person_bbox, face_bbox, frame_num, frame_data, active_track_ids=None,
                         camera_id=-1):
        """
        ã€æœ€ç»ˆç‰ˆ V3ï¼Œæ›¿æ¢ process_track_finalã€‘
        å¼•å…¥ "ç¡®è®¤-æ›´æ–° åˆ†ç¦»" å’Œ "ç½®ä¿¡åº¦ç´¯ç§¯" æœºåˆ¶ï¼Œä»¥å¯¹æŠ—ä¸ç¨³å®šçš„ReIDç‰¹å¾ã€‚
        """
        print(f"ğŸ” PROCESS_TRACK_V3: Track {track_id} å¼€å§‹å¤„ç†ï¼Œframe_num={frame_num}")

        # 1. åˆå§‹åŒ–æˆ–è·å–trackç¼“å­˜
        if track_id not in self.track_cache:
            self.track_cache[track_id] = {
                'person_id': None,
                'status': 'unconfirmed',
                'confirming_id': None,
                'confirming_count': 0,
                'last_feat_frame': -1,
                'last_display_status': 'new',
                'last_reid_sim': 0.0,
                'last_face_sim': 0.0,
                'camera_id': -1  # æ–°å¢ï¼šè®°å½•trackæ‰€å±çš„æ‘„åƒå¤´ID
            }
        track_info = self.track_cache[track_id]
        # è®¾ç½®trackçš„æ‘„åƒå¤´ID
        track_info['camera_id'] = camera_id

        # ã€æ–°å¢ã€‘æ™ºèƒ½èŠ‚æµé€»è¾‘ - æ ¹æ®ç›®æ ‡çŠ¶æ€å†³å®šæå–é¢‘ç‡
        status = track_info['status']
        last_frame = track_info.get('last_feat_frame', -1)
        frame_diff = frame_num - last_frame if last_frame != -1 else float('inf')

        # æ ¹æ®çŠ¶æ€å†³å®šæå–é—´éš” - æ–°ç›®æ ‡æ›´é¢‘ç¹ï¼Œå·²ç¡®è®¤ç›®æ ‡é™ä½é¢‘ç‡
        if status in ['unconfirmed', 'confirming']:
            interval = 5  # æ–°ç›®æ ‡æ¯5å¸§æå–ä¸€æ¬¡ï¼Œå°½å¿«ç¡®è®¤èº«ä»½
        else:
            interval = 15  # å·²ç¡®è®¤ç›®æ ‡æ¯15å¸§æ›´æ–°ä¸€æ¬¡ï¼Œå‡å°‘è®¡ç®—é‡

        # æ™ºèƒ½èŠ‚æµé€»è¾‘
        if frame_diff < interval:
            throttled_reid_feature = track_info.get('last_reid_feature', None)
            return (track_info['person_id'], track_info['last_reid_sim'],
                    track_info['last_face_sim'], 'throttled', throttled_reid_feature)
        else:
            # --- ç‰¹å¾æå– ---
            track_info['last_feat_frame'] = frame_num

            reid_feature = self.extract_person_feature(frame_data, person_bbox)
            face_feature = None
            if face_bbox:
                x, y, w, h = map(int, face_bbox)
                face_crop = frame_data[y:y + h, x:x + w]
                face_feature = self.face_extractor.extract_face_feature(face_crop)
                if face_feature is not None:
                    self.face_inference_count += 1  # å¢åŠ äººè„¸æ¨ç†è®¡æ•°å™¨
            if reid_feature is None and face_feature is None:
                return (track_info['person_id'], 0.0, 0.0, 'no_feature', None)

        # ã€æ–°å¢ã€‘ä¼˜å…ˆæ£€æŸ¥çŸ­æœŸè®°å¿†ï¼ˆé®æŒ¡æ¶ˆå¤±çš„ç›®æ ‡ï¼‰
        person_id_from_memory, sim_from_memory = self.find_in_short_term_memory(reid_feature)
        if person_id_from_memory and sim_from_memory >= self.REID_REACQUISITION_THRESHOLD:
            matched_id = person_id_from_memory
            match_source = 'memory'  # æ ‡è®°ä¸ºæ¥è‡ªçŸ­æœŸè®°å¿†
            reid_sim = sim_from_memory
            face_id = None
            face_sim = 0.0
        else:
            # å¦‚æœçŸ­æœŸè®°å¿†æ²¡æœ‰åŒ¹é…ï¼Œå†è¿›è¡Œå¸¸è§„çš„å…¨å±€åŒ¹é…
            if active_track_ids is None:
                active_track_ids = set()
            (face_id, face_sim), (reid_id, reid_sim) = self.find_best_matches(reid_feature, face_feature, track_id,
                                                                              active_track_ids)

            matched_id = None
            match_source = 'none'

            # ã€ä¿®æ”¹å†³ç­–é€»è¾‘ã€‘ä½¿ç”¨åŒå±‚é˜ˆå€¼
            # å†³ç­–1ï¼šäººè„¸åŒ¹é…æˆåŠŸï¼Œç›´æ¥ç¡®è®¤ (æƒå¨æ€§æœ€é«˜)
            if face_id and face_sim >= FACE_SIMILARITY_THRESHOLD:
                matched_id = face_id
                match_source = 'face'

            # å†³ç­–2ï¼šå¦‚æœtrackå·²ç»æœ‰å…³è”IDï¼Œä½¿ç”¨é«˜é˜ˆå€¼è¿›è¡Œ"æŒç»­ç¡®è®¤"
            elif track_info['person_id'] and reid_id == track_info[
                'person_id'] and reid_sim >= self.REID_CONFIRMATION_THRESHOLD:
                matched_id = reid_id
                match_source = 'reid_confirm'

            # å†³ç­–3ï¼šå¦‚æœtrackæ˜¯æ–°çš„ï¼Œä½¿ç”¨è¾ƒä½çš„"å¯»å›é˜ˆå€¼"åœ¨å…¨å±€åº“ä¸­åŒ¹é…
            elif not track_info['person_id'] and reid_id and reid_sim >= self.REID_REACQUISITION_THRESHOLD:
                matched_id = reid_id
                match_source = 'reid_reacquire'
            else:
                # æ²¡æœ‰è¾¾åˆ°ä»»ä½•åŒ¹é…é˜ˆå€¼
                matched_id = None
                match_source = 'none'

        # --- çŠ¶æ€æœºæµè½¬ ---
        current_person_id = track_info['person_id']

        # åœºæ™¯1ï¼šæ‰¾åˆ°äº†ä¸€ä¸ªåŒ¹é… (æ— è®ºæ˜¯è„¸è¿˜æ˜¯ReID)
        if matched_id:

            # ã€æ–°å¢ã€‘äººè„¸è¦†ç›–é€»è¾‘
            # å¦‚æœå½“å‰trackå·²æœ‰å…³è”çš„IDï¼Œä½†æ–°çš„äººè„¸åŒ¹é…æŒ‡å‘äº†å¦ä¸€ä¸ªID
            current_person_id = track_info.get('person_id')
            if match_source == 'face' and current_person_id and current_person_id != matched_id:
                # ç®€å•å¤„ç†ï¼šç›´æ¥è¦†ç›–IDã€‚æœªæ¥å¯å®ç°åŸå‹åˆå¹¶ã€‚
                track_info['person_id'] = matched_id
                track_info['confirming_id'] = matched_id
                track_info['confirming_count'] = self.CONFIRMATION_COUNT_THRESHOLD  # äººè„¸ç›´æ¥ç¡®è®¤
                # è§£é”æ—§IDçš„åŸå‹
                if current_person_id in self.person_prototypes:
                    self.person_prototypes[current_person_id]['locked_by'] = None

            # å¦‚æœåŒ¹é…åˆ°çš„IDå’Œæˆ‘ä»¬æ­£åœ¨ç¡®è®¤çš„æ˜¯åŒä¸€ä¸ªID
            if matched_id == track_info['confirming_id']:
                track_info['confirming_count'] += 1
                print(f"ğŸ” PROCESS_TRACK_V3: Track {track_id} ç¡®è®¤è®¡æ•°å¢åŠ : {track_info['confirming_count']}")
            # å¦‚æœåŒ¹é…åˆ°äº†ä¸€ä¸ªæ–°IDï¼Œæˆ–è€…ä¹‹å‰æ²¡æœ‰åœ¨ç¡®è®¤çš„ID
            else:
                track_info['confirming_id'] = matched_id
                track_info['confirming_count'] = 1
                print(f"ğŸ” PROCESS_TRACK_V3: Track {track_id} å¼€å§‹ç¡®è®¤æ–°ID: {matched_id}, è®¡æ•°é‡ç½®ä¸º1")

            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç¡®è®¤é˜ˆå€¼
            is_confirmed_by_count = track_info['confirming_count'] >= self.CONFIRMATION_COUNT_THRESHOLD
            is_confirmed_by_face = (match_source == 'face')
            print(
                f"ğŸ” PROCESS_TRACK_V3: Track {track_id} ç¡®è®¤æ£€æŸ¥: count_threshold={is_confirmed_by_count}, face_source={is_confirmed_by_face}")

            # åªè¦æ»¡è¶³ä»»ä¸€ç¡®è®¤æ¡ä»¶
            if is_confirmed_by_count or is_confirmed_by_face:
                # èº«ä»½æ­£å¼ç¡®è®¤ï¼
                confirmed_person_id = track_info['confirming_id']
                # é˜²æ­¢IDåœ¨ç¡®è®¤æœŸé—´è¢«å…¶ä»–é€»è¾‘æ”¹å˜
                if track_info.get('person_id') != confirmed_person_id:
                    print(f"âœ… [ID-CONFIRMED] Track {track_id} -> {confirmed_person_id} by {match_source}")

                track_info['person_id'] = confirmed_person_id
                track_info['status'] = 'confirmed'

                # ã€å…³é”®ã€‘åªæœ‰åœ¨ç¡®è®¤åï¼Œæ‰æ›´æ–°åŸå‹ä»¥é˜²æ­¢æ±¡æŸ“
                self.update_prototypes(confirmed_person_id, track_id, reid_feature, face_feature, camera_id)
                self.person_match_count += 1  # å¢åŠ åŒ¹é…è®¡æ•°å™¨

            # è¿˜æ²¡è¾¾åˆ°ç¡®è®¤é˜ˆå€¼ï¼Œåªæ˜¯åœ¨"ç¡®è®¤ä¸­"
            else:
                track_info['status'] = 'confirming'
                # æš‚æ—¶å°†person_idæŒ‡å‘æ­£åœ¨ç¡®è®¤çš„idï¼Œç”¨äºæ˜¾ç¤ºï¼Œä½†ä¸æ›´æ–°åŸå‹
                current_person_id = track_info['confirming_id']

        # åœºæ™¯2ï¼šæ²¡æœ‰æ‰¾åˆ°ä»»ä½•åŒ¹é…
        else:
            # é‡ç½®ç¡®è®¤è¿‡ç¨‹
            track_info['confirming_id'] = None
            track_info['confirming_count'] = 0

            # å¦‚æœä¹‹å‰æ˜¯å·²ç¡®è®¤çŠ¶æ€ï¼Œç°åœ¨è·Ÿä¸¢äº†ï¼Œå¯ä»¥æš‚æ—¶ä¿æŒæ—§IDä¸€æ®µæ—¶é—´
            if track_info['status'] == 'confirmed':
                pass  # ä¿æŒ current_person_id
            # å¦‚æœä¹‹å‰å°±æ²¡ç¡®è®¤ï¼Œç°åœ¨ä¹Ÿæ²¡åŒ¹é…ä¸Šï¼Œé‚£å°±æ˜¯æ–°äºº
            else:
                if current_person_id is None:  # é¿å…è¦†ç›–ä¸€ä¸ªæ­£åœ¨ç¡®è®¤ä¸­çš„ID
                    self.person_creation_count += 1
                    current_person_id = f"person_{self.person_creation_count:04d}"
                    self.update_prototypes(current_person_id, track_id, reid_feature, face_feature,
                                           camera_id)  # æ–°äººç›´æ¥åˆ›å»ºå¹¶æ›´æ–°
                    track_info['person_id'] = current_person_id
                    track_info['status'] = 'confirmed'  # æ–°äººç›´æ¥å°±æ˜¯ç¡®è®¤çŠ¶æ€

        # --- æ›´æ–°ç”¨äºæ˜¾ç¤ºçš„çŠ¶æ€ ---
        track_info['last_display_status'] = track_info['status']
        track_info['last_reid_sim'] = reid_sim
        track_info['last_face_sim'] = face_sim
        track_info['last_reid_feature'] = reid_feature  # ä¿å­˜reidç‰¹å¾ä¾›èŠ‚æµæ—¶ä½¿ç”¨

        return current_person_id, reid_sim, face_sim, track_info['status'], reid_feature

    def periodic_log(self, frame_num, active_track_ids):
        """
        ã€æ€§èƒ½ä¼˜åŒ–ã€‘å‘¨æœŸæ€§æ—¥å¿—è¾“å‡º
        - å‡å°‘é«˜é¢‘printå¸¦æ¥çš„I/Oé˜»å¡
        - æä¾›ç³»ç»ŸçŠ¶æ€æ¦‚è§ˆ
        """
        self.log_counter += 1

        if self.log_counter >= self.log_interval:
            self.log_counter = 0

            print(
                f"ğŸ“Š ç³»ç»ŸçŠ¶æ€(å¸§#{frame_num}): "
                f"æ´»åŠ¨ç›®æ ‡={len(active_track_ids) if active_track_ids else 0}, "
                f"å·²æ³¨å†Œäººå‘˜={len(self.person_prototypes)}, "
                f"ReID/Faceæ¨ç†={self.reid_inference_count}/{self.face_inference_count}, "
                f"åˆ›å»º/åŒ¹é…={self.person_creation_count}/{self.person_match_count}, "
                f"çŸ­æœŸè®°å¿†={len(self.recently_disappeared_tracks)}, "
                f"ç¼“å­˜Tracks={len(self.track_cache)}"
            )


# å…¨å±€å˜é‡è·Ÿè¸ªREIDçŠ¶æ€
reid_status = {}  # track_id -> {'person_id': str, 'confirmed': bool, 'similarity': float}

# å…¨å±€FastReIDå®ä¾‹
fastreid_system = FastReIDDatabase()


def migrate_database(self, old_filename, new_filename=None):
    """
    æ•°æ®åº“è¿ç§»å·¥å…·ï¼šå°†æ—§ç‰ˆæœ¬æ•°æ®åº“å‡çº§åˆ°V5.0æ ¼å¼
    """
    if new_filename is None:
        new_filename = old_filename.replace('.json', '_v5.json')

    print(f"ğŸ”„ å¼€å§‹æ•°æ®åº“è¿ç§»: {old_filename} -> {new_filename}")

    # åŠ è½½æ—§æ•°æ®åº“
    if not self.load_database(old_filename):
        print("âŒ æ— æ³•åŠ è½½æºæ•°æ®åº“")
        return False

    # ä¿å­˜ä¸ºæ–°æ ¼å¼
    if not self.save_database(new_filename):
        print("âŒ æ— æ³•ä¿å­˜æ–°æ ¼å¼æ•°æ®åº“")
        return False

    print(f"âœ… æ•°æ®åº“è¿ç§»å®Œæˆï¼")
    print(f"   æ–°æ•°æ®åº“: {new_filename}")


# æ•°æ®åº“åˆå§‹åŒ–å‡½æ•°
def initialize_database(args):
    """
    ã€å®Œæ•´æœ€ç»ˆç‰ˆã€‘åˆå§‹åŒ–æ•°æ®åº“åŠŸèƒ½ï¼Œæ­£ç¡®å¤„ç†æ¸…ç†ã€å¯¼å‡ºç­‰å‘½ä»¤è¡Œæ“ä½œã€‚
    """

    # --- æ­¥éª¤ 1: æ£€æŸ¥æ˜¯å¦æ˜¯ç‰¹æ®Šæ“ä½œå‘½ä»¤ï¼ˆæ¸…ç†æˆ–å¯¼å‡ºï¼‰ ---
    # è¿™äº›å‘½ä»¤éœ€è¦å…ˆåŠ è½½æ•°æ®åº“ï¼Œæ‰§è¡Œæ“ä½œï¼Œç„¶åé€€å‡ºç¨‹åºã€‚

    if args.export_summary or args.cleanup_db:

        print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        print("âš™ï¸  æ‰§è¡Œæ•°æ®åº“ç»´æŠ¤å‘½ä»¤...")
        print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

        # é¦–å…ˆï¼Œæ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™æ— æ³•æ“ä½œã€‚
        if not os.path.exists(args.db_file):
            print(f"âŒ é”™è¯¯: æ•°æ®åº“æ–‡ä»¶ '{args.db_file}' ä¸å­˜åœ¨ï¼Œæ— æ³•æ‰§è¡Œæ“ä½œã€‚")
            return False  # è¿”å›Falseï¼Œè®©ä¸»ç¨‹åºé€€å‡º

        # åŠ è½½æ•°æ®åº“åˆ°å†…å­˜
        print(f"ğŸ“‚ æ­£åœ¨ä» '{args.db_file}' åŠ è½½æ•°æ®åº“...")
        if not fastreid_system.load_database(args.db_file):
            print(f"âŒ é”™è¯¯: åŠ è½½æ•°æ®åº“ '{args.db_file}' å¤±è´¥ï¼Œæ— æ³•ç»§ç»­ã€‚")
            return False  # è¿”å›Falseï¼Œè®©ä¸»ç¨‹åºé€€å‡º

        print("âœ… æ•°æ®åº“åŠ è½½æˆåŠŸã€‚")
        print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

        # --- æ ¹æ®å‘½ä»¤æ‰§è¡Œå…·ä½“æ“ä½œ ---

        if args.export_summary:
            print("âœï¸  æ­£åœ¨å¯¼å‡ºæ•°æ®åº“æ‘˜è¦...")
            fastreid_system.export_database_summary("database_summary.txt")
            print("âœ… æ‘˜è¦å·²æˆåŠŸå¯¼å‡ºåˆ° 'database_summary.txt'ã€‚")

        if args.cleanup_db:
            print("ğŸ§¹  æ­£åœ¨æ¸…ç†æ•°æ®åº“ä¸­çš„è¿‡æœŸæ•°æ®...")
            # æ‰§è¡Œæ¸…ç†æ“ä½œï¼Œå¯ä»¥æŒ‡å®šæ—¶é—´çª—å£ï¼ˆä¾‹å¦‚ï¼Œåªä¿ç•™æœ€è¿‘1å°æ—¶çš„æ•°æ®ï¼‰
            fastreid_system.cleanup_database(time_window=3600)

            print("\nğŸ’¾  æ­£åœ¨ä¿å­˜æ¸…ç†åçš„æ•°æ®åº“...")
            # æ¸…ç†åè‡ªåŠ¨ä¿å­˜ï¼Œä»¥æŒä¹…åŒ–æ›´æ”¹
            if fastreid_system.save_database(args.db_file):
                print("âœ… æ¸…ç†åçš„æ•°æ®åº“å·²æˆåŠŸä¿å­˜ã€‚")
            else:
                print("âŒ é”™è¯¯: ä¿å­˜æ¸…ç†åçš„æ•°æ®åº“å¤±è´¥ï¼")

        print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        print("âœ… æ•°æ®åº“ç»´æŠ¤æ“ä½œå®Œæˆï¼Œç¨‹åºå°†é€€å‡ºã€‚")

        # è¿”å›Falseï¼Œå‘Šè¯‰ä¸»ç¨‹åºä¸éœ€è¦å¯åŠ¨GStreamerç®¡çº¿ï¼Œç›´æ¥é€€å‡ºå³å¯
        return False

    # --- æ­¥éª¤ 2: æ­£å¸¸çš„å¯åŠ¨æµç¨‹ ---
    # å¦‚æœæ²¡æœ‰ç‰¹æ®Šå‘½ä»¤ï¼Œåˆ™æ‰§è¡Œå¸¸è§„çš„ç¨‹åºå¯åŠ¨åŠ è½½ã€‚

    print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print("ğŸš€  ç³»ç»Ÿæ­£å¸¸å¯åŠ¨...")
    print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

    # å°è¯•åŠ è½½ç°æœ‰æ•°æ®åº“ï¼ˆå¦‚æœå­˜åœ¨æˆ–è¢«å‘½ä»¤è¡ŒæŒ‡å®šï¼‰
    if args.load_db or os.path.exists(args.db_file):
        print(f"ğŸ“‚ æ­£åœ¨å°è¯•ä» '{args.db_file}' åŠ è½½æ•°æ®åº“...")
        if fastreid_system.load_database(args.db_file):
            print("âœ… æ•°æ®åº“åŠ è½½æˆåŠŸï¼Œå‡†å¤‡è¿è¡Œç®¡çº¿ã€‚")
        else:
            # æ–‡ä»¶ä¸å­˜åœ¨æˆ–åŠ è½½å¤±è´¥éƒ½ä¸æ˜¯è‡´å‘½é”™è¯¯ï¼Œç¨‹åºå¯ä»¥ç»§ç»­å¹¶åˆ›å»ºæ–°æ•°æ®åº“
            print(f"âš ï¸  è­¦å‘Š: æ•°æ®åº“ '{args.db_file}' ä¸å­˜åœ¨æˆ–åŠ è½½å¤±è´¥ï¼Œå°†åœ¨è¿è¡Œæ—¶åˆ›å»ºæ–°æ•°æ®åº“ã€‚")
    else:
        print("â„¹ï¸  ä¿¡æ¯: æœªæ‰¾åˆ°ç°æœ‰æ•°æ®åº“ï¼Œå°†åœ¨è¿è¡Œæ—¶åˆ›å»ºæ–°æ•°æ®åº“ã€‚")

    # è¿”å›Trueï¼Œå‘Šè¯‰ä¸»ç¨‹åºç»§ç»­æ‰§è¡Œï¼Œå¯åŠ¨GStreamerç®¡çº¿
    return True


def cleanup_database(args):
    """æ¸…ç†æ•°æ®åº“åŠŸèƒ½"""
    if not args.no_save:
        print("ğŸ’¾ ä¿å­˜REIDæ•°æ®åº“...")
        if fastreid_system.save_database(args.db_file):
            print("âœ… REIDæ•°æ®åº“ä¿å­˜å®Œæˆ")
        else:
            print("âŒ REIDæ•°æ®åº“ä¿å­˜å¤±è´¥")

    # æ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“Š æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   äººå‘˜æ€»æ•°: {len(fastreid_system.person_prototypes)}")
    print(f"   Trackç¼“å­˜: {len(fastreid_system.track_cache)}")
    print(f"   åˆ›å»ºæ¬¡æ•°: {fastreid_system.person_creation_count}")
    print(f"   åŒ¹é…æ¬¡æ•°: {getattr(fastreid_system, 'person_match_count', 0)}")  # ä½¿ç”¨getattré¿å…æœªå®šä¹‰é”™è¯¯
    print(f"   å¤„ç†å¸§æ•°: {fastreid_system.total_frames_processed}")
    print(f"   æ¨ç†æ¬¡æ•°: {fastreid_system.reid_inference_count}")
    print(f"   æ•°æ®åº“æ–‡ä»¶: {args.db_file}")


def normalize_bbox_to_target(bbox, frame_width, frame_height, target_width, target_height):
    """å°†è¾¹ç•Œæ¡†åæ ‡æ ‡å‡†åŒ–åˆ°ç›®æ ‡åˆ†è¾¨ç‡ - å…³é”®ä¿®å¤"""
    # æ­£ç¡®ç†è§£ï¼šæ¨¡å‹æ¨ç†åœ¨ 960x544 ä¸Šè¿›è¡Œï¼Œå¾—åˆ° 960x544 åæ ‡
    # æ˜¾ç¤ºåœ¨ 1280x720 ä¸Šï¼Œéœ€è¦å°†åæ ‡ä» 960x544 æ˜ å°„åˆ° 1280x720
    # ä½†æ˜¯æ˜ å°„åº”è¯¥æ˜¯æŒ‰æ¯”ä¾‹ç¼©æ”¾ï¼Œä¸æ˜¯æ”¾å¤§ï¼

    if frame_width == target_width and frame_height == target_height:
        # åˆ†è¾¨ç‡ç›¸åŒï¼Œä¸éœ€è¦è½¬æ¢
        return [int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])]

    # æ­£ç¡®çš„ç¼©æ”¾ï¼šä»æ¨ç†åˆ†è¾¨ç‡åˆ°æ˜¾ç¤ºåˆ†è¾¨ç‡
    # æ¨¡å‹æ¨ç†åœ¨ 960x544ï¼Œæ˜¾ç¤ºåœ¨ 1280x720
    # æ‰€ä»¥éœ€è¦å°†åæ ‡ä» 960x544 æ˜ å°„åˆ° 1280x720
    scale_x = target_width / frame_width
    scale_y = target_height / frame_height

    left = int(bbox[0] * scale_x)
    top = int(bbox[1] * scale_y)
    width = int(bbox[2] * scale_x)
    height = int(bbox[3] * scale_y)

    # è¾¹ç•Œæ£€æŸ¥
    left = max(0, min(left, target_width - width))
    top = max(0, min(top, target_height - height))
    width = max(1, min(width, target_width - left))
    height = max(1, min(height, target_height - top))

    return [left, top, width, height]


def fix_bbox_coordinates(raw_bbox, display_width, display_height):
    """ä¿®å¤è¾¹ç•Œæ¡†åæ ‡ - å…³é”®ä¿®å¤"""
    # å…³é”®ä¿®å¤ï¼šæ ¹æ®æ¨¡å‹æ¨ç†åˆ†è¾¨ç‡(960x544)å’Œæ˜¾ç¤ºåˆ†è¾¨ç‡(1280x720)çš„æ¯”ä¾‹è¿›è¡Œç¼©æ”¾
    # æ¨¡å‹åœ¨960x544ä¸Šæ¨ç†ï¼Œä½†æ˜¾ç¤ºåœ¨1280x720ä¸Š

    # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
    scale_x = display_width / 960  # 1280/960 = 1.333
    scale_y = display_height / 544  # 720/544 = 1.324

    # ä»æ¨¡å‹æ¨ç†åæ ‡ç¼©æ”¾åˆ°æ˜¾ç¤ºåæ ‡
    left = int(raw_bbox[0] * scale_x)
    top = int(raw_bbox[1] * scale_y)
    width = int(raw_bbox[2] * scale_x)
    height = int(raw_bbox[3] * scale_y)

    # å®‰å…¨é™åˆ¶ï¼šç¡®ä¿è¾¹ç•Œæ¡†ä¸ä¼šè¿‡å¤§
    max_display_width = display_width * 0.5  # æœ€å¤§50%æ˜¾ç¤ºå®½åº¦
    max_display_height = display_height * 0.8  # æœ€å¤§80%æ˜¾ç¤ºé«˜åº¦

    if width > max_display_width:
        width = int(max_display_width)
    if height > max_display_height:
        height = int(max_display_height)

    # è¾¹ç•Œæ£€æŸ¥
    left = max(0, min(left, display_width - width))
    top = max(0, min(top, display_height - height))
    width = max(1, min(width, display_width - left))
    height = max(1, min(height, display_height - top))

    return [left, top, width, height]


def fix_bbox_coordinates_multi(raw_bbox, display_width, display_height, source_index, num_sources):
    """å¤šè·¯ç‰ˆæœ¬è¾¹ç•Œæ¡†åæ ‡ä¿®å¤ - è€ƒè™‘tilerå¸ƒå±€"""
    # é¦–å…ˆæŒ‰å•è·¯æ–¹å¼è®¡ç®—åæ ‡
    bbox = fix_bbox_coordinates(raw_bbox, display_width, display_height)

    # è®¡ç®—tilerå¸ƒå±€åç§»
    # å‡è®¾tileræ˜¯1è¡ŒNåˆ—å¸ƒå±€
    tile_width = TILER_OUTPUT_WIDTH // num_sources  # æ¯ä¸ªtileçš„å®½åº¦
    tile_height = TILER_OUTPUT_HEIGHT  # æ¯ä¸ªtileçš„é«˜åº¦

    # è®¡ç®—åœ¨tilerä¸­çš„åç§»
    offset_x = source_index * tile_width
    offset_y = 0  # å•è¡Œå¸ƒå±€ï¼ŒYåç§»ä¸º0

    # åº”ç”¨tileråç§»
    left = bbox[0] + offset_x
    top = bbox[1] + offset_y
    width = bbox[2]
    height = bbox[3]

    return [left, top, width, height]


def is_bbox_inside(inner_bbox, outer_bbox, tolerance=0.95):
    """æ£€æŸ¥å†…æ¡†æ˜¯å¦å®Œå…¨åœ¨å¤–æ¡†å†…ï¼ˆå¸¦å®¹å¿åº¦ï¼‰"""
    ix, iy, iw, ih = inner_bbox
    ox, oy, ow, oh = outer_bbox

    # æ£€æŸ¥å†…æ¡†çš„å››ä¸ªè§’æ˜¯å¦éƒ½åœ¨å¤–æ¡†å†…
    inner_left = ix
    inner_right = ix + iw
    inner_top = iy
    inner_bottom = iy + ih

    outer_left = ox
    outer_right = ox + ow
    outer_top = oy
    outer_bottom = oy + oh

    # è®¡ç®—å†…æ¡†åœ¨å¤–æ¡†å†…çš„é¢ç§¯æ¯”ä¾‹
    x_overlap_left = max(inner_left, outer_left)
    x_overlap_right = min(inner_right, outer_right)
    y_overlap_top = max(inner_top, outer_top)
    y_overlap_bottom = min(inner_bottom, outer_bottom)

    if x_overlap_right < x_overlap_left or y_overlap_bottom < y_overlap_top:
        return False

    overlap_area = (x_overlap_right - x_overlap_left) * (y_overlap_bottom - y_overlap_top)
    inner_area = iw * ih

    # é‡å é¢ç§¯å¿…é¡»å å†…æ¡†é¢ç§¯çš„ä¸€å®šæ¯”ä¾‹
    return (overlap_area / inner_area) >= tolerance if inner_area > 0 else False


def get_true_frame_resolution(pipeline):
    """è·å–çœŸæ­£çš„å¸§åˆ†è¾¨ç‡"""
    # DeepStream 7.1 ä¸­ï¼ŒçœŸæ­£çš„å¸§åˆ†è¾¨ç‡é€šå¸¸ç”± streammux å†³å®š
    # æˆ–è€…ä»è§£ç å™¨è¾“å‡ºå†³å®š
    # è¿”å›é»˜è®¤çš„æ¨ç†åˆ†è¾¨ç‡
    return MODEL_INPUT_WIDTH, MODEL_INPUT_HEIGHT


def tiler_src_pad_buffer_probe(pad, info, u_data):
    """
    ã€DeepStream 7.1 æ€§èƒ½ä¼˜åŒ–ç‰ˆã€‘
    - å»é™¤é«˜é¢‘printè¯­å¥ï¼Œå‡å°‘I/Oé˜»å¡
    - ç§»é™¤ä¸å¿…è¦çš„sorted()æ“ä½œ
    - ä¿ç•™æ ¸å¿ƒçš„"å¸§å†…IDé”"é€»è¾‘
    """
    uris = u_data if u_data else []

    try:
        gst_buffer = info.get_buffer()
        if not gst_buffer: return Gst.PadProbeReturn.OK

        batch_meta = pyds.gst_buffer_get_nvds_batch_meta(hash(gst_buffer))
        if not batch_meta: return Gst.PadProbeReturn.OK

    except Exception as e:
        print(f"âŒ [PROBE-CRITICAL] è·å–bufferæˆ–batch metadataå¤±è´¥: {e}")
        return Gst.PadProbeReturn.OK

    if not hasattr(tiler_src_pad_buffer_probe, 'frame_counter'):
        tiler_src_pad_buffer_probe.frame_counter = 0
    else:
        tiler_src_pad_buffer_probe.frame_counter += 1
    current_frame_num = tiler_src_pad_buffer_probe.frame_counter

    l_frame = batch_meta.frame_meta_list
    while l_frame is not None:
        try:
            frame_meta = pyds.NvDsFrameMeta.cast(l_frame.data)
            fastreid_system.total_frames_processed += 1

            frame_data = None
            try:
                surface = pyds.get_nvds_buf_surface(hash(gst_buffer), frame_meta.batch_id)
                if surface is not None:
                    arr = np.array(surface, copy=True, order='C')
                    if len(arr.shape) == 3 and arr.shape[2] == 4:
                        frame_data = cv2.cvtColor(arr, cv2.COLOR_RGBA2BGR)
                    elif len(arr.shape) == 3 and arr.shape[2] == 3:
                        frame_data = cv2.cvtColor(arr, cv2.COLOR_RGB2BGR)
                    else:
                        l_frame = l_frame.next
                        continue
            except RuntimeError:
                l_frame = l_frame.next
                continue

            if frame_data is None:
                l_frame = l_frame.next
                continue

            persons_in_frame, faces_in_frame = {}, []
            l_obj = frame_meta.obj_meta_list
            while l_obj is not None:
                try:
                    obj_meta = pyds.NvDsObjectMeta.cast(l_obj.data)
                    raw_bbox = [obj_meta.rect_params.left, obj_meta.rect_params.top, obj_meta.rect_params.width,
                                obj_meta.rect_params.height]
                except Exception:
                    l_obj = l_obj.next
                    continue

                src_idx = frame_meta.pad_index
                batch_size = len(uris)
                bbox = fix_bbox_coordinates_multi(raw_bbox, MUXER_OUTPUT_WIDTH, MUXER_OUTPUT_HEIGHT, src_idx,
                                                  batch_size)

                if obj_meta.class_id == 0:
                    persons_in_frame[obj_meta.object_id] = (bbox, obj_meta)
                elif obj_meta.class_id == 2:
                    faces_in_frame.append(bbox)
                l_obj = l_obj.next

            person_to_face_map = {}
            for track_id, (person_bbox, _) in persons_in_frame.items():
                for face_bbox in faces_in_frame:
                    if is_bbox_inside(face_bbox, person_bbox):
                        person_to_face_map[track_id] = face_bbox
                        break

            active_track_ids = set(persons_in_frame.keys())

            # ã€æ€§èƒ½ä¼˜åŒ–ã€‘ç”¨äºé˜²æ­¢åŒä¸€å¸§å†…ä¸€ä¸ªperson_idè¢«å¤šä¸ªtrackå ç”¨çš„"å¸§å†…é”"
            claimed_person_ids_in_frame = set()

            # ã€æ€§èƒ½ä¼˜åŒ–ã€‘ç§»é™¤ sorted()ï¼Œç›´æ¥è¿­ä»£å­—å…¸
            for track_id, (person_bbox, obj_meta) in persons_in_frame.items():
                face_bbox = person_to_face_map.get(track_id)

                src_idx = frame_meta.pad_index
                local_id = obj_meta.object_id
                global_track_id = (src_idx << 32) | local_id

                person_id, reid_sim, face_sim, status, reid_feature = fastreid_system.process_track_v3(
                    global_track_id, person_bbox, face_bbox, current_frame_num,
                    frame_data, active_track_ids, src_idx
                )

                # --- ã€æ ¸å¿ƒä¿®å¤é€»è¾‘ - ä¿ç•™ã€‘ ---
                if person_id and person_id in claimed_person_ids_in_frame:
                    # ã€æ€§èƒ½ä¼˜åŒ–ã€‘åªåœ¨å‘ç”Ÿå…³é”®å†²çªæ—¶æ‰“å°ï¼Œè€Œä¸æ˜¯æ¯ä¸€å¸§éƒ½æ‰“å°
                    print(
                        f"ğŸš¨ [ID-CONFLICT] Frame {current_frame_num}: Track {global_track_id} è¯•å›¾è®¤é¢†å·²è¢«å ç”¨çš„ ID {person_id}ã€‚å¼ºåˆ¶é‡ç½®ï¼")
                    if global_track_id in fastreid_system.track_cache:
                        track_info = fastreid_system.track_cache[global_track_id]
                        track_info.update({'status': 'unconfirmed', 'confirming_id': None, 'confirming_count': 0})
                    person_id = None  # æ¸…é™¤person_idï¼Œåç»­é€»è¾‘ä¼šå°†å…¶ä½œä¸ºæœªè¯†åˆ«å¤„ç†
                elif person_id:
                    claimed_person_ids_in_frame.add(person_id)

                # --- ReIDç‰¹å¾æ³¨å…¥é€»è¾‘ (ä¸å˜) ---
                if reid_feature is not None:
                    try:
                        user_meta = pyds.nvds_acquire_user_meta_from_pool(batch_meta)
                        if user_meta:
                            custom_struct = pyds.alloc_custom_struct(user_meta)

                            custom_struct.structId = reid_feature.shape[0]
                            feature_str = ",".join(map(str, reid_feature.astype(np.float32)))
                            custom_struct.message = feature_str
                            custom_struct.message = pyds.get_string(custom_struct.message)
                            custom_struct.sampleInt = int(reid_feature.shape[0])

                            user_meta.user_meta_data = custom_struct
                            user_meta.base_meta.meta_type = pyds.NvDsMetaType.NVDS_USER_META

                            pyds.nvds_add_user_meta_to_obj(obj_meta, user_meta)
                    except Exception as e:
                        pass  # é™é»˜å¤„ç†ç‰¹å¾æ³¨å…¥é”™è¯¯

                # --- ã€V3 æ˜¾ç¤ºé€»è¾‘ - æ€§èƒ½ä¼˜åŒ–ç‰ˆã€‘---
                display_text = ""
                border_color = (0.0, 1.0, 0.0, 1.0)  # Green (é»˜è®¤æœªè¯†åˆ«)

                if person_id:
                    track_info = fastreid_system.track_cache.get(global_track_id, {})
                    current_status = track_info.get('status', 'unconfirmed')

                    sim_text = ""
                    if face_sim >= FACE_SIMILARITY_THRESHOLD:
                        sim_text = f"F:{face_sim:.2f}"
                    elif reid_sim > 0:
                        sim_text = f"R:{reid_sim:.2f}"

                    if current_status == 'confirmed':
                        border_color = (1.0, 0.0, 0.0, 1.0)  # Red
                        if track_info.get('last_face_sim', 0) >= FACE_SIMILARITY_THRESHOLD:
                            border_color = (1.0, 0.64, 0.0, 1.0)  # Orange
                    elif current_status == 'confirming':
                        border_color = (1.0, 1.0, 0.0, 1.0)  # Yellow
                    else:  # unconfirmed
                        border_color = (0.0, 0.0, 1.0, 1.0)  # Blue

                    status_short = {'unconfirmed': 'U', 'confirming': 'C', 'confirmed': 'OK'}.get(current_status, 'U')
                    display_text = f"{person_id} {sim_text}[{status_short}]"
                else:
                    display_text = f"T:{global_track_id}"

                obj_meta.text_params.display_text = display_text
                obj_meta.text_params.font_params.font_name = "Serif"
                obj_meta.text_params.font_params.font_size = 12
                obj_meta.text_params.font_params.font_color.set(1.0, 1.0, 1.0, 1.0)
                obj_meta.rect_params.border_color.set(*border_color)
                obj_meta.rect_params.border_width = 3

            fastreid_system.cleanup_stale_tracks(active_track_ids)

            # ã€æ€§èƒ½ä¼˜åŒ–ã€‘ä½¿ç”¨æ–°çš„å‘¨æœŸæ€§æ—¥å¿—ç³»ç»Ÿ
            fastreid_system.periodic_log(current_frame_num, active_track_ids)

        except Exception as e:
            import traceback
            print(f"âŒ Probe Error in Frame Loop: {e}")
            traceback.print_exc()

        l_frame = l_frame.next
    return Gst.PadProbeReturn.OK


def check_pipeline_elements(pipeline):
    """æ£€æŸ¥ç®¡çº¿å…ƒç´ æ˜¯å¦æ­£ç¡®åˆ›å»ºå’Œæ·»åŠ """
    print("ğŸ” æ£€æŸ¥ç®¡çº¿å…ƒç´ ...")

    try:
        # æ–¹æ³•1: ä½¿ç”¨ChildProxyæ¥å£
        elements = pipeline.get_by_interface(Gst.ChildProxy)
        if elements:
            print("âœ… ä½¿ç”¨ChildProxyæ¥å£è·å–å…ƒç´ :")
            try:
                # å°è¯•ä¸åŒçš„æ–¹æ³•è·å–å­å…ƒç´ æ•°é‡
                if hasattr(elements, 'get_children'):
                    children = elements.get_children()
                    num_elements = len(children)
                    print(f"   å­å…ƒç´ æ•°é‡: {num_elements}")
                    for i, child in enumerate(children):
                        print(f"   {i}: {child.get_name()} ({child.get_factory().get_name()}")
                elif hasattr(elements, 'get_property') and elements.get_property('num-children'):
                    num_elements = elements.get_property('num-children')
                    print(f"   å­å…ƒç´ æ•°é‡: {num_elements}")
                    for i in range(num_elements):
                        child = elements.get_property_nth(i)
                        if child:
                            print(f"   {i}: {child.get_name()} ({child.get_factory().get_name()}")
                else:
                    print("   æ— æ³•è·å–å­å…ƒç´ æ•°é‡ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
                    # å¤‡ç”¨æ–¹æ³•ï¼šéå†pipelineä¸­çš„æ‰€æœ‰å…ƒç´ 
                    _dump_pipeline_elements(pipeline)
            except Exception as e:
                print(f"âš ï¸ ChildProxyæ–¹æ³•å¤±è´¥: {e}")
                # å¤‡ç”¨æ–¹æ³•ï¼šéå†pipelineä¸­çš„æ‰€æœ‰å…ƒç´ 
                _dump_pipeline_elements(pipeline)
        else:
            print("âŒ æ— æ³•è·å–ChildProxyæ¥å£ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
            # å¤‡ç”¨æ–¹æ³•ï¼šéå†pipelineä¸­çš„æ‰€æœ‰å…ƒç´ 
            _dump_pipeline_elements(pipeline)

    except Exception as e:
        print(f"âš ï¸ æ£€æŸ¥ç®¡çº¿å…ƒç´ æ—¶å‡ºé”™: {e}")
        # å¤‡ç”¨æ–¹æ³•ï¼šéå†pipelineä¸­çš„æ‰€æœ‰å…ƒç´ 
        _dump_pipeline_elements(pipeline)

    # æ£€æŸ¥ç®¡çº¿çŠ¶æ€
    try:
        state = pipeline.get_state(Gst.State.NULL)
        print(f"ğŸ“Š ç®¡çº¿çŠ¶æ€: {state}")
    except Exception as e:
        print(f"âš ï¸ è·å–ç®¡çº¿çŠ¶æ€å¤±è´¥: {e}")


def _dump_pipeline_elements(pipeline):
    """å¤‡ç”¨æ–¹æ³•ï¼šéå†ç®¡çº¿ä¸­çš„æ‰€æœ‰å…ƒç´ """
    print("ğŸ“¦ ä½¿ç”¨å¤‡ç”¨æ–¹æ³•éå†ç®¡çº¿å…ƒç´ :")

    # è·å–pipelineä¸­çš„æ‰€æœ‰å…ƒç´ 
    try:
        elements = []

        def traverse_elements(element, depth=0):
            elements.append((element, depth))
            # å°è¯•è·å–å­å…ƒç´ 
            try:
                if hasattr(element, 'get_children'):
                    children = element.get_children()
                    for child in children:
                        traverse_elements(child, depth + 1)
            except:
                pass

        traverse_elements(pipeline)

        print(f"   æ€»è®¡å…ƒç´ æ•°é‡: {len(elements)}")
        for i, (element, depth) in enumerate(elements):
            indent = "  " * depth
            name = element.get_name() or "Unknown"
            factory = element.get_factory().get_name() if element.get_factory() else "Unknown"
            print(f"   {i}: {indent}{name} ({factory})")

    except Exception as e:
        print(f"âŒ å¤‡ç”¨æ–¹æ³•ä¹Ÿå¤±è´¥: {e}")
        # æœ€åçš„å¤‡ç”¨æ–¹æ³•
        print("   ğŸ†˜ æœ€åå¤‡ç”¨æ–¹æ³•ï¼šåˆ—å‡ºå·²çŸ¥å…ƒç´ ")
        known_elements = ["source", "h264parser", "decoder", "streammux", "pgie", "tracker",
                          "nvvidconv1", "nvvidconv2", "nvosd", "sink"]
        for i, elem_name in enumerate(known_elements):
            print(f"   {i}: {elem_name} (é¢„æœŸ)")


def create_source_bin(index, uri):
    """åˆ›å»ºå•è·¯æºçš„source bin - ä½¿ç”¨DeepStream 7.1å®˜æ–¹API"""
    bin_name = f"source-bin-{index}"
    nbin = Gst.Bin.new(bin_name)
    if not nbin:
        sys.stderr.write(" Unable to create source bin \n")

    # ä½¿ç”¨uridecodebinè‡ªåŠ¨é€‚é…æ ¼å¼
    uri_decode_bin = Gst.ElementFactory.make("uridecodebin", f"uri-decode-{index}")
    if not uri_decode_bin:
        sys.stderr.write(" Unable to create uri decode bin \n")

    uri_decode_bin.set_property("uri", uri)

    # ä¸ºRTSPæºæ·»åŠ ä¼˜åŒ–é…ç½®
    if uri.startswith("rtsp://"):
        print(f"ğŸ”§ ä¸ºRTSPæº{index}åº”ç”¨ä¼˜åŒ–é…ç½®")
        uri_decode_bin.set_property("buffer-duration", 2000000)  # 2ç§’ç¼“å†²
        uri_decode_bin.set_property("buffer-size", 0)  # è‡ªåŠ¨ç¼“å†²å¤§å°
        uri_decode_bin.set_property("download", False)  # ä¸ä¸‹è½½æ•´ä¸ªæ–‡ä»¶
        uri_decode_bin.set_property("use-buffering", True)  # å¯ç”¨ç¼“å†²

    # è¿æ¥å›è°ƒå‡½æ•°
    uri_decode_bin.connect("pad-added", cb_newpad, nbin)
    uri_decode_bin.connect("child-added", decodebin_child_added, None)

    nbin.add(uri_decode_bin)

    # åˆ›å»ºghost padï¼Œç¨åä¼šè®¾ç½®target
    bin_pad = nbin.add_pad(Gst.GhostPad.new_no_target("src", Gst.PadDirection.SRC))
    if not bin_pad:
        sys.stderr.write(" Failed to add ghost pad in source bin \n")
        return None

    return nbin


def cb_newpad(decodebin, decoder_src_pad, data):
    """å¤„ç†decodebinçš„padæ·»åŠ å›è°ƒ - ä½¿ç”¨å®˜æ–¹API"""
    print("In cb_newpad\n")
    caps = decoder_src_pad.get_current_caps()
    if not caps:
        caps = decoder_src_pad.query_caps()
    gststruct = caps.get_structure(0)
    gstname = gststruct.get_name()
    source_bin = data
    features = caps.get_features(0)

    print("gstname=", gstname)
    if gstname.find("video") != -1:
        print("features=", features)
        if features.contains("memory:NVMM"):
            # è·å–source binçš„ghost padå¹¶è®¾ç½®target
            bin_ghost_pad = source_bin.get_static_pad("src")
            if not bin_ghost_pad.set_target(decoder_src_pad):
                sys.stderr.write("Failed to link decoder src pad to source bin ghost pad\n")
        else:
            sys.stderr.write(" Error: Decodebin did not pick nvidia decoder plugin.\n")


def bus_call(bus, message, loop):
    t = message.type
    if t == Gst.MessageType.EOS:
        print("ğŸ“º è§†é¢‘æ’­æ”¾ç»“æŸ")
        loop.quit()
    elif t == Gst.MessageType.ERROR:
        err, debug = message.parse_error()
        print(f"âŒ é”™è¯¯: {err.message}")
        print(f"ğŸ” è¯¦ç»†ä¿¡æ¯: {debug}")
        loop.quit()
    elif t == Gst.MessageType.WARNING:
        err, debug = message.parse_warning()
        print(f"âš ï¸ è­¦å‘Š: {err.message}")
    elif t == Gst.MessageType.INFO:
        if message.src:
            src_name = message.src.get_name()
            print(f"â„¹ï¸ ä¿¡æ¯: {src_name} - {message.parse_info()}")
    elif t == Gst.MessageType.STATE_CHANGED:
        if message.src:
            old, new, pending = message.parse_state_changed()
            src_name = message.src.get_name()
            print(f"ğŸ”„ çŠ¶æ€å˜åŒ–: {src_name} {old} -> {new} (pending: {pending})")
    elif t == Gst.MessageType.STREAM_STATUS:
        if message.src:
            try:
                type_, owner = message.parse_stream_status()
                print(f"ğŸ“Š æµçŠ¶æ€: {owner.get_name()} - {type_}")
            except Exception as e:
                print(f"âš ï¸ è§£ææµçŠ¶æ€å¤±è´¥: {e}")
    elif t == Gst.MessageType.ELEMENT:
        # å…ƒç´ ç‰¹å®šæ¶ˆæ¯
        structure = message.get_structure()
        if structure and structure.has_field("message"):
            msg_text = structure.get_value("message")
            print(f"ğŸ“¦ å…ƒç´ æ¶ˆæ¯: {msg_text}")
    return True


# RTSPåŠ¨æ€padå¤„ç†å‡½æ•°
def cb_new_pad(rtspsrc, new_pad, queue):
    """å¤„ç†rtspsrcçš„åŠ¨æ€padç”Ÿæˆ"""
    # å·²ç»è¿è¿‡å°±è¿”å›
    if new_pad.is_linked():
        print("âš ï¸ Padå·²ç»è¿æ¥è¿‡ï¼Œè·³è¿‡")
        return

    # å¤„ç† H264 å’Œ H265 çš„ rtp æµ
    caps = new_pad.get_current_caps()
    if caps:
        s = caps.to_string()
        print(f"ğŸ” æ£€æŸ¥caps: {s}")
        if not ("application/x-rtp" in s and "media=(string)video" in s):
            print("âš ï¸ éè§†é¢‘RTPæµï¼Œè·³è¿‡")
            return

        # æ ¹æ®ç¼–ç ç±»å‹é€‰æ‹©ä¸åŒçš„depayloader
        if "H265" in s or "h265" in s:
            print("ğŸ“¹ æ£€æµ‹åˆ°H265è§†é¢‘æµ")
            # ä½¿ç”¨H265å¤„ç†é“¾è·¯
            try:
                # é“¾æ¥ queue -> h265_depay -> h265_parse -> decoder
                queue.link(rtsp_h265_depay)
                rtsp_h265_depay.link(rtsp_h265_parse)
                rtsp_h265_parse.link(rtsp_decoder)
                print("âœ… H265å¤„ç†é“¾è·¯é“¾æ¥æˆåŠŸ")
            except Exception as e:
                print(f"âŒ H265å¤„ç†é“¾è·¯é“¾æ¥å¤±è´¥: {e}")
                return
        elif "H264" in s or "h264" in s:
            print("ğŸ“¹ æ£€æµ‹åˆ°H264è§†é¢‘æµ")
            # ä½¿ç”¨H264å¤„ç†é“¾è·¯
            try:
                # é“¾æ¥ queue -> h264_depay -> h264_parse -> decoder
                queue.link(rtsp_h264_depay)
                rtsp_h264_depay.link(rtsp_h264_parse)
                rtsp_h264_parse.link(rtsp_decoder)
                print("âœ… H264å¤„ç†é“¾è·¯é“¾æ¥æˆåŠŸ")
            except Exception as e:
                print(f"âŒ H264å¤„ç†é“¾è·¯é“¾æ¥å¤±è´¥: {e}")
                return
        else:
            print("âš ï¸ æœªçŸ¥çš„è§†é¢‘ç¼–ç æ ¼å¼ï¼Œè·³è¿‡")
            return

    sink_pad = queue.get_static_pad("sink")
    if sink_pad.is_linked():
        print("âš ï¸ Queue sink padå·²è¿æ¥ï¼Œè·³è¿‡")
        return

    ret = new_pad.link(sink_pad)
    if ret == Gst.PadLinkReturn.OK:
        print("âœ… rtspsrc pad -> queue.sink è¿æ¥æˆåŠŸ")
        print(f"ğŸ”— è¿æ¥è¯¦æƒ…: {new_pad.get_name()} -> {sink_pad.get_parent().get_name()}")
    else:
        print(f"âŒ rtspsrc pad è¿æ¥å¤±è´¥: {ret}")


def decodebin_child_added(child_proxy, object, name, user_data):
    """å¤„ç†decodebinçš„å­å…ƒç´ æ·»åŠ """
    print(f"ğŸ”§ decodebinæ–°å¢å­å…ƒç´ : {name}")
    if name == "source":
        # å¯¹RTSPæºè¿›è¡Œé…ç½®
        try:
            object.set_property('latency', 200)
            object.set_property('drop-on-latency', True)
            print("âœ… RTSPæºå±æ€§è®¾ç½®æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ è®¾ç½®RTSPæºå±æ€§å¤±è´¥: {e}")


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='FastReID Market1501é›†æˆç³»ç»Ÿ - å¤šè·¯ç‰ˆæœ¬')
    parser.add_argument("--sources", nargs='+', required=True,
                        help="æœ€å¤š 6 æ¡ uriï¼ˆrtsp:// æˆ– æ–‡ä»¶è·¯å¾„ï¼Œå¦‚ rtsp://ç”¨æˆ·:å¯†ç @IP è§†é¢‘æ–‡ä»¶.mp4ï¼‰")
    parser.add_argument("--test-video", default="sample_720p.h264",
                        help="æµ‹è¯•è§†é¢‘æ–‡ä»¶è·¯å¾„")

    # --- ã€ä¿®æ”¹éƒ¨åˆ†ã€‘ ---
    # æ•°æ®åº“ç›¸å…³å‚æ•°
    parser.add_argument("--load-db", action="store_true",
                        help="å¯åŠ¨æ—¶åŠ è½½ç°æœ‰æ•°æ®åº“")
    # åˆ é™¤äº† --save-db å‚æ•°ï¼Œå› ä¸ºä¿å­˜æ˜¯é»˜è®¤è¡Œä¸º
    parser.add_argument("--no-save", action="store_true",
                        help="ç¨‹åºé€€å‡ºæ—¶ä¸ä¿å­˜æ•°æ®åº“ï¼ˆé»˜è®¤ä¼šä¿å­˜ï¼‰")
    parser.add_argument("--export-summary", action="store_true",
                        help="å¯¼å‡ºæ•°æ®åº“æ‘˜è¦å¹¶é€€å‡º")
    parser.add_argument("--cleanup-db", action="store_true",
                        help="æ¸…ç†è¿‡æœŸæ•°æ®å¹¶é€€å‡º")
    parser.add_argument("--db-file", default="fastreid_database.json",
                        help="æŒ‡å®šæ•°æ®åº“æ–‡ä»¶è·¯å¾„")

    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()

    # æ£€æŸ¥è¾“å…¥æºæ•°é‡
    uris = args.sources
    batch_size = len(uris)
    if batch_size > 6:
        print("âš ï¸  ç›®å‰æœ€å¤šæ”¯æŒ 6 è·¯è§†é¢‘æº")
        sys.exit(1)

    # è½¬æ¢ä¸ºæ­£ç¡®çš„URIæ ¼å¼
    for i, uri in enumerate(uris):
        if not uri.startswith("rtsp://") and not uri.startswith("file://"):
            # æœ¬åœ°æ–‡ä»¶éœ€è¦file://åè®®
            abs_path = os.path.abspath(uri)
            uris[i] = f"file://{abs_path}"

    print(f"ğŸ¯ å¤šè·¯æ··åˆè¯†åˆ«ç³»ç»Ÿå¯åŠ¨ V4.2 [FastReID + Buffalo_Läººè„¸è¯†åˆ«] - å¤šè·¯ç‰ˆ")
    print(f"ğŸ“Š æ”¯æŒ {batch_size} è·¯è§†é¢‘æº:")
    for i, uri in enumerate(uris):
        source_type = "RTSP" if uri.startswith("rtsp://") else "FILE"
        print(f"   æº{i}: {uri} ({source_type})")

    # éªŒè¯æ‰€æœ‰æ–‡ä»¶æº
    for i, uri in enumerate(uris):
        if not uri.startswith("rtsp://"):
            # ä»file:// URIä¸­æå–æ–‡ä»¶è·¯å¾„
            file_path = uri[7:] if uri.startswith("file://") else uri
            if not os.path.isfile(file_path):
                print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                if i == 0 and os.path.isfile(args.test_video):
                    print(f"ğŸ”„ å°è¯•ä½¿ç”¨æµ‹è¯•è§†é¢‘: {args.test_video}")
                    uris[0] = f"file://{os.path.abspath(args.test_video)}"
                    print(f"âœ… ä½¿ç”¨æµ‹è¯•è§†é¢‘: {uris[0]}")
                else:
                    print(f"âŒ æµ‹è¯•è§†é¢‘ä¹Ÿä¸å­˜åœ¨: {args.test_video}")
                    sys.exit(1)

    # å°è¯•æ£€æµ‹è§†é¢‘åˆ†è¾¨ç‡
    def get_video_resolution(video_path):
        """å°è¯•æ£€æµ‹è§†é¢‘åˆ†è¾¨ç‡"""
        try:
            import cv2
            cap = cv2.VideoCapture(video_path)
            if cap.isOpened():
                ret, frame = cap.read()
                if ret:
                    height, width = frame.shape[:2]
                    cap.release()
                    return width, height
                cap.release()
        except:
            pass
        return MUXER_OUTPUT_WIDTH, MUXER_OUTPUT_HEIGHT  # ä½¿ç”¨é¢„è®¾åˆ†è¾¨ç‡

    # æ£€æµ‹å®é™…è§†é¢‘åˆ†è¾¨ç‡ï¼ˆå¦‚æœæ˜¯RTSPï¼Œä½¿ç”¨é»˜è®¤åˆ†è¾¨ç‡ï¼‰
    has_rtsp = any(uri.startswith("rtsp://") for uri in uris)
    if has_rtsp:
        input_frame_width, input_frame_height = MUXER_OUTPUT_WIDTH, MUXER_OUTPUT_HEIGHT
        print(f"ğŸ“¹ RTSPæµä½¿ç”¨é»˜è®¤åˆ†è¾¨ç‡: {input_frame_width}x{input_frame_height}")
    else:
        input_frame_width, input_frame_height = get_video_resolution(uris[0])
        print(f"ğŸ“¹ æ£€æµ‹åˆ°è§†é¢‘åˆ†è¾¨ç‡: {input_frame_width}x{input_frame_height}")

    print("ğŸ¯ æ··åˆè¯†åˆ«ç³»ç»Ÿå¯åŠ¨ V4.2 [FastReID + Buffalo_Läººè„¸è¯†åˆ«] - ä¿®å¤ç‰ˆ")
    print("ğŸ“Š åŠŸèƒ½ï¼šå¤šè·¯äººå‘˜æ£€æµ‹ + äººè„¸æ£€æµ‹ + OSNet ReID + Buffalo_Läººè„¸ç‰¹å¾ + æ··åˆåŒ¹é…")
    print("ğŸš€ V4.2æ–°å¢ï¼šæ”¯æŒå¤šè·¯è§†é¢‘æºåŒæ—¶å¤„ç†ï¼Œå…±äº«åŒä¸€å¥—ReIDæ•°æ®åº“")
    print("ğŸš€ V4.2æ–°å¢ï¼šå…¨å±€track_idç¡®ä¿è·¨æ‘„åƒå¤´å”¯ä¸€æ€§")
    print("ğŸš€ V3æ–°å¢ï¼šç¡®è®¤-æ›´æ–°åˆ†ç¦»æœºåˆ¶ï¼Œå¯¹æŠ—ä¸ç¨³å®šçš„ReIDç‰¹å¾")
    print("ğŸš€ V3æ–°å¢ï¼šç½®ä¿¡åº¦ç´¯ç§¯ç³»ç»Ÿï¼Œéœ€è¦è¿ç»­3æ¬¡åŒ¹é…æ‰ç¡®è®¤èº«ä»½")
    print("ğŸš€ V3æ–°å¢ï¼šäººè„¸ä¸€ç¥¨ç¡®è®¤æƒï¼Œå¼ºåŒ–äººè„¸è¯†åˆ«çš„æƒå¨æ€§")
    print("ğŸ”§ ä¿®å¤ï¼šè§£å†³IDæ¼‚ç§»å’Œé®æŒ¡é‡è¯†åˆ«å¤±è´¥é—®é¢˜")
    print("ğŸ”§ ä¿®å¤ï¼šå¸§æ•°æ®è·å–é—®é¢˜å·²ä¿®å¤ï¼Œä½¿ç”¨nvosd sink pad + CUDAç»Ÿä¸€å†…å­˜")
    print("ğŸ”§ ä¿®å¤ï¼šè¾¹ç•Œæ¡†è¿‡å¤§é—®é¢˜å·²ä¿®å¤ï¼Œå‚è€ƒdeepstream-test2çš„ç»Ÿä¸€åˆ†è¾¨ç‡ç³»ç»Ÿ")
    print("ğŸ”§ ä¿®å¤ï¼šé‡‡ç”¨æ¨¡å‹æ¨ç†åˆ†è¾¨ç‡(960x544)å’Œæ˜¾ç¤ºåˆ†è¾¨ç‡(1280x720)çš„åˆ†ç¦»ç³»ç»Ÿ")
    print(
        f"ğŸ“ åˆ†è¾¨ç‡ç³»ç»Ÿ: æ¨¡å‹{MODEL_INPUT_WIDTH}x{MODEL_INPUT_HEIGHT} -> æ˜¾ç¤º{MUXER_OUTPUT_WIDTH}x{MUXER_OUTPUT_HEIGHT}")
    print("âš™ï¸  é…ç½®ï¼š")
    print(f"   ReIDç‰¹å¾ç»´åº¦: {REID_FEATURE_DIM} (å®˜æ–¹OSNet-IBN)")
    print(f"   äººè„¸ç‰¹å¾ç»´åº¦: {FACE_FEATURE_DIM} (Buffalo_L)")
    print(f"   äººè„¸æƒé‡: {FACE_WEIGHT}, ReIDæƒé‡: {REID_WEIGHT}")
    print(f"   æ··åˆé˜ˆå€¼: {HYBRID_SCORE_THRESHOLD}, äººè„¸é˜ˆå€¼: {FACE_SIMILARITY_THRESHOLD}")
    print(f"   æ—¶é—´çª—å£: {PATROL_TIME_WINDOW}ç§’")
    print(f"   ReIDæ¨¡å‹: osnet_ibn_x1_0_market1501 (å®˜æ–¹é¢„è®­ç»ƒ)")
    print(f"   äººè„¸æ¨¡å‹: Buffalo_L (w600k_r50.onnx)")
    print(f"   è§†é¢‘æºæ•°é‡: {batch_size}")
    print(f"   DeepStreamç‰ˆæœ¬: 7.1")
    print(f"   Ubuntuç‰ˆæœ¬: 22.04")
    print("ğŸ” V4.2ç‰ˆæœ¬é¢œè‰²æ ‡è¯†ï¼š")
    print("   ğŸ”µ è“è‰² (unconfirmed): æ–°ç›®æ ‡ï¼Œæœªç¡®è®¤")
    print("   ğŸŸ¡ é»„è‰² (confirming): æ­£åœ¨ç¡®è®¤ä¸­ï¼Œè¿ç»­åŒ¹é…1-2æ¬¡")
    print("   ğŸ”´ çº¢è‰² (confirmed by ReID): ReIDè¿ç»­ç¡®è®¤3æ¬¡ä»¥ä¸Š")
    print("   ğŸŸ  æ©™è‰² (confirmed by Face): äººè„¸ä¸€ç¥¨ç¡®è®¤")
    print("   ğŸŸ¢ ç»¿è‰²: å®Œå…¨æœªè¯†åˆ«çš„è·Ÿè¸ªç›®æ ‡")
    print("ğŸ¯ Probeä½ç½®: nvosd sink pad + CUDAç»Ÿä¸€å†…å­˜ï¼Œç¡®ä¿CPUå¯è®¿é—®")
    print("-" * 50)

    # åˆå§‹åŒ–GStreamer
    GObject.threads_init()  # <--- NEW: ç¡®ä¿GLib/GObjectçº¿ç¨‹å®‰å…¨
    Gst.init(None)

    # æ£€æŸ¥æ–‡ä»¶
    if not check_model_files():
        print("âŒ æ¨¡å‹æ–‡ä»¶æ£€æŸ¥å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
        sys.exit(1)

    # åˆå§‹åŒ–æ•°æ®åº“
    if not initialize_database(args):
        print("ğŸ“Š æ•°æ®åº“æ“ä½œå®Œæˆï¼Œç¨‹åºé€€å‡º")
        sys.exit(0)

    # åˆ›å»ºç®¡çº¿
    pipeline = Gst.Pipeline.new("fastreid-market1501")

    # åˆ›å»ºå¤šè·¯source bin
    source_bins = []
    for i, uri in enumerate(uris):
        source_bin = create_source_bin(i, uri)
        pipeline.add(source_bin)
        source_bins.append(source_bin)
        print(f"âœ… åˆ›å»ºæº{i}: {uri}")

    print("âœ… å¤šè·¯source binåˆ›å»ºæˆåŠŸ")

    # åˆ›å»ºå…ƒç´ 
    streammux = Gst.ElementFactory.make("nvstreammux", "stream-muxer")
    pgie = Gst.ElementFactory.make("nvinfer", "primary-inference")
    tracker = Gst.ElementFactory.make("nvtracker", "tracker")

    # æ·»åŠ tilerå…ƒç´ è§£å†³å¤šè·¯è§†é¢‘æ‹¼æ¥é—®é¢˜
    tiler = Gst.ElementFactory.make("nvmultistreamtiler", "tiler")
    if not tiler:
        print("âŒ tilerå…ƒç´ åˆ›å»ºå¤±è´¥ï¼")
        sys.exit(1)
    print("âœ… tilerå…ƒç´ åˆ›å»ºæˆåŠŸ")

    # ä½¿ç”¨DeepStream 7.1æ¨èç»“æ„ - ç¡®ä¿æ­£ç¡®çš„æ ¼å¼è½¬æ¢
    nvvidconv_pretiler = Gst.ElementFactory.make("nvvideoconvert", "nvvidconv-pretiler")
    nvvidconv1 = Gst.ElementFactory.make("nvvideoconvert", "nvvidconv1")
    nvvidconv2 = Gst.ElementFactory.make("nvvideoconvert", "nvvidconv2")
    nvosd = Gst.ElementFactory.make("nvdsosd", "onscreendisplay")

    # é…ç½®nvdsosdä»¥æ˜¾ç¤ºè‡ªå®šä¹‰æ ‡ç­¾
    # æ³¨æ„ï¼šDeepStream 7.1ä¸­nvdsosdçš„å±æ€§åå¯èƒ½ä¸åŒ
    try:
        nvosd.set_property("display-text", 1)  # ç¡®ä¿æ˜¾ç¤ºæ–‡æœ¬
    except Exception as e:
        print(f"âš ï¸ è®¾ç½®display-textå¤±è´¥: {e}")

    try:
        # å°è¯•å¸¸è§çš„æ–‡æœ¬è¾¹è·å±æ€§å
        possible_padding_props = [
            "text-padding", "bbox-text-padding", "padding",
            "text-margin", "bbox-margin", "margin"
        ]
        for prop in possible_padding_props:
            try:
                nvosd.set_property(prop, 5)
                print(f"âœ… æˆåŠŸè®¾ç½® {prop} = 5")
                break
            except:
                continue
    except Exception as e:
        print(f"âš ï¸ è®¾ç½®æ–‡æœ¬è¾¹è·å¤±è´¥: {e}")

    # æ˜¾ç¤ºå…ƒç´  - ä½¿ç”¨æ ‡å‡†æ˜¾ç¤º
    if Gst.ElementFactory.find("nveglglessink"):
        sink = Gst.ElementFactory.make("nveglglessink", "nvvideo-renderer")
    else:
        sink = Gst.ElementFactory.make("fakesink", "fake-renderer")

    # ä¿®å¤ç®¡çº¿è¿æ¥ï¼šæ·»åŠ å¿…è¦çš„è½¬æ¢å…ƒç´ 
    nvvidconv_postosd = Gst.ElementFactory.make("nvvideoconvert", "nvvidconv-postosd")
    # nvegltransform = Gst.ElementFactory.make("nvegltransform", "nvegl-transform") # ç³»ç»Ÿä¸æ”¯æŒ

    # åˆ›å»ºelementsåˆ—è¡¨
    elements = [streammux, pgie, tracker, nvvidconv_pretiler, tiler, nvvidconv1, nvvidconv2, nvosd, nvvidconv_postosd,
                sink]
    check_elements = [streammux, pgie, tracker, nvvidconv_pretiler, tiler, nvvidconv1, nvvidconv2, nvosd,
                      nvvidconv_postosd, sink]
    element_names = ["streammux", "pgie", "tracker", "nvvidconv_pretiler", "tiler", "nvvidconv1", "nvvidconv2", "nvosd",
                     "nvvidconv_postosd", "sink"]

    if not all(elements):
        print("âŒ åˆ›å»ºGStreamerå…ƒç´ å¤±è´¥")
        for elem, name in zip(check_elements, element_names):
            if elem is None:
                print(f"   âŒ å…ƒç´ åˆ›å»ºå¤±è´¥: {name}")
        if 'capsfilter' in locals() and capsfilter is None:
            print("   âš ï¸  capsfilteråˆ›å»ºå¤±è´¥ï¼Œå°†ä¸ä½¿ç”¨capsfilter")
        return

    # è®¾ç½®å…ƒç´ å±æ€§ - å‚è€ƒ deepstream-test2ï¼šä½¿ç”¨ç»Ÿä¸€åˆ†è¾¨ç‡
    # æ³¨æ„ï¼šRTSPæºçš„å±æ€§å·²ç»åœ¨åˆ›å»ºæ—¶è®¾ç½®

    # è®¾ç½®æµå¤ç”¨å™¨å‚æ•° - æ”¯æŒå¤šè·¯
    streammux.set_property('width', MUXER_OUTPUT_WIDTH)
    streammux.set_property('height', MUXER_OUTPUT_HEIGHT)
    streammux.set_property('batch-size', batch_size)  # è®¾ç½®ä¸ºå®é™…æºæ•°é‡
    streammux.set_property('batched-push-timeout', 2000000)  # å¢åŠ è¶…æ—¶æ—¶é—´é¿å…å¡æ­»
    streammux.set_property('live-source', 1)  # å¤šè·¯æ··åˆï¼Œè®¾ç½®ä¸º1æ”¯æŒRTSP
    streammux.set_property('attach-sys-ts', True)  # é™„åŠ ç³»ç»Ÿæ—¶é—´æˆ³
    streammux.set_property('sync-inputs', True)  # åŒæ­¥è¾“å…¥
    streammux.set_property('max-latency', 2000000)  # æœ€å¤§å»¶è¿Ÿ2ç§’

    # é…ç½®æ–‡ä»¶ - ä½¿ç”¨æ”¯æŒäººè„¸æ£€æµ‹çš„é…ç½®æ–‡ä»¶
    config_file = 'dstest3_tracking_enabled_config.txt'

    # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„é…ç½®æ–‡ä»¶
    print(f"ğŸ”§ ä½¿ç”¨é…ç½®æ–‡ä»¶: {config_file}")
    print(
        "ğŸš¨ é‡è¦æç¤ºï¼šè¯·ç¡®ä¿Peopleneté…ç½®æ–‡ä»¶ä¸­ `[class-attrs-2]` (face) çš„ `pre-cluster-threshold` å·²è®¾ä¸ºè¾ƒä½å€¼ (å¦‚0.4) ä»¥å¯ç”¨äººè„¸æ£€æµ‹!")

    # éªŒè¯é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(config_file):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        sys.exit(1)

    # æ˜¾ç¤ºé…ç½®æ–‡ä»¶å†…å®¹çš„å…³é”®éƒ¨åˆ†
    try:
        with open(config_file, 'r') as f:
            lines = f.readlines()
            print("ğŸ“‹ é…ç½®æ–‡ä»¶å…³é”®å‚æ•°:")
            for i, line in enumerate(lines):
                if 'pre-cluster-threshold' in line or 'detected-max-w' in line or 'detected-max-h' in line:
                    print(f"   {line.strip()}")
    except Exception as e:
        print(f"âŒ è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")

    pgie.set_property('config-file-path', config_file)
    pgie.set_property('batch-size', batch_size)  # è®¾ç½®ä¸ºå®é™…æºæ•°é‡

    # è®¾ç½®è¾“å…¥æºå’Œç›®æ ‡åˆ†è¾¨ç‡
    input_width = 1280  # å…¸å‹çš„720pè§†é¢‘å®½åº¦
    input_height = 720  # å…¸å‹çš„720pè§†é¢‘é«˜åº¦
    target_width = 960  # æ¨¡å‹æ¨ç†åˆ†è¾¨ç‡
    target_height = 544  # æ¨¡å‹æ¨ç†åˆ†è¾¨ç‡

    print(f"ğŸ“ åˆ†è¾¨ç‡è®¾ç½®: è¾“å…¥={input_width}x{input_height} -> ç›®æ ‡={target_width}x{target_height}")

    tracker_config_file = 'config_tracker_NvDCF_person.yml'
    tracker.set_property('ll-lib-file', '/opt/nvidia/deepstream/deepstream/lib/libnvds_nvmultiobjecttracker.so')
    tracker.set_property('ll-config-file', tracker_config_file)
    tracker.set_property('display-tracking-id', 1)  # å¯ç”¨trackerçš„è‡ªåŠ¨æ˜¾ç¤ºä½œä¸ºå¤‡ç”¨

    # è®¾ç½®tilerå±æ€§ - è§£å†³å¤šè·¯è§†é¢‘æ‹¼æ¥é—®é¢˜ï¼Œä¿æŒ16:9æ¯”ä¾‹
    print(f"ğŸ”§ é…ç½®tiler: {batch_size}è·¯è§†é¢‘, æ€»å°ºå¯¸{TILER_OUTPUT_WIDTH}x{TILER_OUTPUT_HEIGHT}")
    tiler.set_property("rows", 1)  # 1è¡Œ
    tiler.set_property("columns", batch_size)  # æ ¹æ®æºæ•°é‡è®¾ç½®åˆ—æ•°
    tiler.set_property("width", TILER_OUTPUT_WIDTH)  # tileræ€»è¾“å‡ºå®½åº¦ (2ä¸ª1280x720è§†é¢‘)
    tiler.set_property("height", TILER_OUTPUT_HEIGHT)  # tileræ€»è¾“å‡ºé«˜åº¦ (ä¿æŒ16:9)
    print(f"âœ… tileré…ç½®å®Œæˆ: æ¯ä¸ªè§†é¢‘{(TILER_OUTPUT_WIDTH // batch_size)}x{TILER_OUTPUT_HEIGHT} (16:9)")

    # é…ç½®tilerå‰çš„æ ¼å¼è½¬æ¢ï¼Œç¡®ä¿è¾“å‡ºRGBAæ ¼å¼
    nvvidconv_pretiler.set_property('nvbuf-memory-type', 0)  # NVBUF_MEM_DEFAULT

    # é…ç½®nvvidconv2ä»¥ç¡®ä¿CPUå¯è®¿é—®çš„æ ¼å¼ - ä½¿ç”¨CUDAç»Ÿä¸€å†…å­˜
    nvvidconv2.set_property('nvbuf-memory-type', 3)  # NVBUF_MEM_CUDA_UNIFIED
    nvvidconv2.set_property('output-buffers', 4)

    # ç¡®ä¿è¾“å‡ºæ ¼å¼ä¸ºRGBAï¼Œä¾¿äºCPUè®¿é—® - ä½¿ç”¨capsfilter
    capsfilter = Gst.ElementFactory.make("capsfilter", "caps-filter")
    if capsfilter:
        caps = Gst.Caps.from_string(
            f"video/x-raw(memory:NVMM), format=RGBA, width={TILER_OUTPUT_WIDTH}, height={TILER_OUTPUT_HEIGHT}")
        capsfilter.set_property("caps", caps)
        elements.append(capsfilter)
    else:
        capsfilter = None

    # æ„å»ºç®¡çº¿ - ä¿®å¤è¿æ¥é—®é¢˜ï¼Œç¡®ä¿æ‰€æœ‰å…ƒç´ éƒ½æ·»åŠ åˆ°pipeline
    # åŸºç¡€å…ƒç´ å·²ç»æ·»åŠ ï¼Œç°åœ¨æ·»åŠ å…¶ä»–å…ƒç´ 
    remaining_elements = [streammux, pgie, tracker, nvvidconv_pretiler, tiler, nvvidconv1, nvvidconv2, nvosd,
                          nvvidconv_postosd, sink]
    if capsfilter:
        remaining_elements.append(capsfilter)

    for element in remaining_elements:
        pipeline.add(element)

    # å¤šè·¯é“¾æ¥åˆ°æµå¤ç”¨å™¨
    try:
        print("ğŸ”— é“¾æ¥å¤šè·¯æºåˆ°æµå¤ç”¨å™¨...")

        # é€è·¯åˆ›å»ºå¹¶æŒ‚åˆ° pipeline
        for i, source_bin in enumerate(source_bins):
            sink_pad = streammux.request_pad_simple(f"sink_{i}")
            src_pad = source_bin.get_static_pad("src")

            if src_pad and sink_pad:
                link_result = src_pad.link(sink_pad)
                if link_result != Gst.PadLinkReturn.OK:
                    print(f"âŒ æº{i} padé“¾æ¥å¤±è´¥: {link_result}")
                    sys.exit(1)
                else:
                    print(f"âœ… æº{i} é“¾æ¥æˆåŠŸ")
            else:
                print(f"âŒ æ— æ³•è·å–æº{i}çš„src padæˆ–streammuxçš„sink pad")
                print(f"   src_pad: {src_pad is not None}")
                print(f"   sink_pad: {sink_pad is not None}")
                sys.exit(1)

    except Exception as e:
        print(f"âŒ å¤šè·¯ç®¡çº¿é“¾æ¥å¤±è´¥: {e}")
        sys.exit(1)

    streammux.link(pgie)
    pgie.link(tracker)
    tracker.link(nvvidconv_pretiler)
    nvvidconv_pretiler.link(tiler)
    tiler.link(nvvidconv1)
    nvvidconv1.link(nvvidconv2)

    # ä¿®å¤nvvidconv2åˆ°nvosdçš„é“¾æ¥ - ä½¿ç”¨capsfilter
    if capsfilter:
        nvvidconv2.link(capsfilter)
        capsfilter.link(nvosd)
    else:
        nvvidconv2.link(nvosd)

    # ä¿®å¤æ˜¾ç¤ºé“¾è·¯ï¼šnvosd -> nvvidconv_postosd -> sink (nvegltransformä¸æ”¯æŒ)
    nvosd.link(nvvidconv_postosd)
    nvvidconv_postosd.link(sink)

    # å°†æ¢é’ˆæŒ‚è½½åˆ° nvosd çš„ sink padï¼Œè¿™æ˜¯æœ€ç¨³å¦¥çš„ä½ç½®
    # ç¡®ä¿æ•°æ®æ˜¯CPUå¯è®¿é—®çš„ï¼Œé¿å…GPUå†…å­˜è®¿é—®é—®é¢˜
    nvosd_sink_pad = nvosd.get_static_pad("sink")
    if not nvosd_sink_pad:
        print("âŒ æ— æ³•è·å– nvosd çš„ sink padï¼")
        sys.exit(1)

    nvosd_sink_pad.add_probe(Gst.PadProbeType.BUFFER, tiler_src_pad_buffer_probe, uris)
    print("âœ… å·²æ·»åŠ REIDå¤„ç†probeå‡½æ•°åˆ° nvosd sink pad (æ¨èä½ç½®)")

    loop = GLib.MainLoop()

    def shutdown_handler(signum, frame):
        print("\nğŸ›‘ æ”¶åˆ°é€€å‡ºä¿¡å·ï¼Œæ­£åœ¨ä¼˜é›…åœ°å…³é—­ç³»ç»Ÿ...")
        loop.quit()

    # --- ã€ä¿®æ”¹éƒ¨åˆ†ï¼šå®šæœŸä¿å­˜é€»è¾‘ã€‘ ---
    def periodic_save_callback():
        # åªæœ‰åœ¨ --no-save æœªè¢«è®¾ç½®æ—¶æ‰æ‰§è¡Œå®šæœŸä¿å­˜
        if not args.no_save:
            print("\nâ³ [è‡ªåŠ¨ä¿å­˜] æ­£åœ¨æ‰§è¡Œå®šæœŸæ•°æ®åº“ä¿å­˜...")
            fastreid_system.save_database(args.db_file, create_backup=False)
        else:
            print("   (æ ¹æ® --no-save å‚æ•°ï¼Œè·³è¿‡è‡ªåŠ¨ä¿å­˜)")
        return True  # è¿”å›Trueè®©å®šæ—¶å™¨ç»§ç»­è¿è¡Œ

    def periodic_cleanup_callback():
        print("\nâ³ [å‘¨æœŸæ€§æ¸…ç†] æ­£åœ¨æ£€æŸ¥ä¸æ´»è·ƒçš„åŸå‹...")
        fastreid_system.cleanup_inactive_prototypes()
        return True  # è¿”å›Trueè®©å®šæ—¶å™¨ç»§ç»­è¿è¡Œ

    import signal
    signal.signal(signal.SIGINT, shutdown_handler)
    signal.signal(signal.SIGTERM, shutdown_handler)

    # åªæœ‰åœ¨éœ€è¦ä¿å­˜æ—¶æ‰å¯åŠ¨å®šæ—¶å™¨ (å³æ²¡æœ‰ --no-save)
    if not args.no_save:
        autosave_interval = 300  # ç§’
        print(f"ğŸ•’ å·²å¯ç”¨æ•°æ®åº“è‡ªåŠ¨ä¿å­˜ï¼Œé—´éš”: {autosave_interval} ç§’")
        GLib.timeout_add_seconds(autosave_interval, periodic_save_callback)
    else:
        print("ğŸš« å·²æ ¹æ® --no-save å‚æ•°ç¦ç”¨æ•°æ®åº“è‡ªåŠ¨ä¿å­˜ã€‚")

    # æ·»åŠ åŸå‹æ¸…ç†å®šæ—¶å™¨
    cleanup_interval = 600  # æ¯10åˆ†é’Ÿ(600ç§’)æ‰§è¡Œä¸€æ¬¡æ¸…ç†
    print(f"ğŸ•’ å·²å¯ç”¨ä¸æ´»è·ƒåŸå‹æ¸…ç†ï¼Œé—´éš”: {cleanup_interval} ç§’")
    GLib.timeout_add_seconds(cleanup_interval, periodic_cleanup_callback)

    bus = pipeline.get_bus()
    bus.add_signal_watch()
    bus.connect("message", bus_call, loop)

    if source_type == "RTSP":
        print("ğŸš€ å¯åŠ¨RTSPæµMarket1501 OSNet FastReIDç®¡çº¿...")
    else:
        print("ğŸš€ å¯åŠ¨æœ¬åœ°è§†é¢‘Market1501 OSNet FastReIDç®¡çº¿...")

    ret = pipeline.set_state(Gst.State.PLAYING)
    if ret == Gst.StateChangeReturn.FAILURE:
        print("âŒ æ— æ³•å°†ç®¡çº¿è®¾ç½®ä¸ºPLAYINGçŠ¶æ€")
        return

    if has_rtsp:
        print("âœ… å¤šè·¯Market1501 OSNet FastReIDç®¡çº¿å¯åŠ¨æˆåŠŸï¼ˆåŒ…å«RTSPæµï¼‰")
        print("â³ ç­‰å¾…RTSPæµåˆå§‹åŒ–... (çº¦10-20ç§’)")

        # ç­‰å¾…ç®¡çº¿å®Œå…¨å¯åŠ¨
        time.sleep(5)

        # æ£€æŸ¥ç®¡çº¿çŠ¶æ€
        state, pending, _ = pipeline.get_state(Gst.State.NULL)
        print(f"ğŸ“Š ç®¡çº¿çŠ¶æ€: {state}")
    else:
        print("âœ… å¤šè·¯Market1501 OSNet FastReIDç®¡çº¿å¯åŠ¨æˆåŠŸï¼ˆæœ¬åœ°æ–‡ä»¶ï¼‰")

    try:
        loop.run()
    except Exception as e:
        print(f"âŒ Glibä¸»å¾ªç¯è¿è¡Œæ—¶å‘ç”Ÿé”™è¯¯: {e}")
    finally:
        print("ğŸ§¹ æ­£åœ¨åœæ­¢ç®¡çº¿å¹¶æ¸…ç†èµ„æº...")
        pipeline.set_state(Gst.State.NULL)

        # --- ã€æ ¸å¿ƒä¿®å¤ï¼šæœ€ç»ˆä¿å­˜é€»è¾‘ã€‘ ---
        # åªè¦æ²¡æœ‰æŒ‡å®š --no-saveï¼Œå°±æ‰§è¡Œæœ€ç»ˆä¿å­˜
        if not args.no_save:
            print("ğŸ’¾ æ­£åœ¨æ‰§è¡Œæœ€ç»ˆçš„æ•°æ®åº“ä¿å­˜...")
            fastreid_system.save_database(args.db_file, create_backup=True)
        else:
            print("ğŸš« æ ¹æ® --no-save å‚æ•°ï¼Œè·³è¿‡æœ€ç»ˆçš„æ•°æ®åº“ä¿å­˜ã€‚")

        print("âœ… Market1501 OSNetç³»ç»Ÿå·²å®Œå…¨åœæ­¢ (V4.2ä¿®å¤ç‰ˆ)")

    print("\nğŸ“‹ ä½¿ç”¨è¯´æ˜ï¼ˆå¤šè·¯ç‰ˆæœ¬ï¼‰ï¼š")
    print("   å¤šè·¯RTSP: python3 fastreid_integration.py --sources rtsp://ç”¨æˆ·:å¯†ç @IP1 rtsp://ç”¨æˆ·:å¯†ç @IP2")
    print("   å¤šè·¯æ–‡ä»¶: python3 fastreid_integration.py --sources video1.mp4 video2.mp4")
    print("   æ··åˆè¾“å…¥: python3 fastreid_integration.py --sources rtsp://ç”¨æˆ·:å¯†ç @IP video1.mp4")
    print("   æµ‹è¯•è§†é¢‘: python3 fastreid_integration.py --sources sample_720p.h264")
    print(f"   å½“å‰è¾“å…¥æº: {uris}")


if __name__ == "__main__":
    main()
